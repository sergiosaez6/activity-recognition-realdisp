{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos necesarios. Asegurarse de poder importarlos.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pylab import rcParams\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import os as os\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "from time import time\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\n",
      "3.6.8 (default, Aug 20 2019, 17:12:48) \n",
      "[GCC 8.3.0]\n",
      "sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12-FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['01', '02', '03', '05', '08', '09', '10', '11', '13', '14', '16', '17']\n",
    "global activities\n",
    "activities = [9,10,11,12,13,19,20,21,24,25,31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(cm1):\n",
    "    temp = 0\n",
    "    TruePositive = np.diag(cm1)\n",
    "    FalsePositive = []\n",
    "    for i in range(len(activities)):\n",
    "        FalsePositive.append(sum(cm1[:,i]) - cm1[i,i])\n",
    "    FalseNegative = []\n",
    "    for i in range(len(activities)):\n",
    "        FalseNegative.append(sum(cm1[i,:]) - cm1[i,i])\n",
    "    TrueNegative = []\n",
    "    for i in range(len(activities)):\n",
    "        temp = np.delete(cm1, i, 0)   # delete ith row\n",
    "        temp = np.delete(temp, i, 1)  # delete ith column\n",
    "        TrueNegative.append(sum(sum(temp)))\n",
    "    \n",
    "    return(TruePositive, FalsePositive, TrueNegative, FalseNegative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustado a los datos\n",
    "n_time_steps = 128\n",
    "n_classes = 11 # Nº de clases (el 0 está eliminado)\n",
    "n_channels = 1 # Nº de canales\n",
    "n_columns = 40\n",
    "\n",
    "# Podríamos variarlo\n",
    "batch_size = 128 # Tamaño del batch\n",
    "learning_rate = 1e-3 # Learning rate (por defecto es 0.001)\n",
    "epochs = 100 # Épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 1  #################################################################\n",
      "Test subject: 01\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 211   1   4   0   0   0]\n",
      " [  0   0   0   0   0  59 157   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 168   0  48]\n",
      " [  0   0   0   0   0   0   0   0   9 207   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 216 216 211 157 216 168 207 215]\n",
      "False Positive:  [ 0  0  0  0  0 59  1  4  9  0 48]\n",
      "True Negative:  [2159 2159 2159 2159 2159 2100 2158 2155 2150 2159 2112]\n",
      "False Negative:  [ 0  0  0  0  0  5 59  0 48  9  0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9490526315789474\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      0.781     0.977     0.868       216\n",
      "           6      0.994     0.727     0.840       216\n",
      "           7      0.982     1.000     0.991       216\n",
      "           8      0.949     0.778     0.855       216\n",
      "           9      1.000     0.958     0.979       216\n",
      "          10      0.817     1.000     0.900       215\n",
      "\n",
      "    accuracy                          0.949      2375\n",
      "   macro avg      0.957     0.949     0.948      2375\n",
      "weighted avg      0.957     0.949     0.948      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t0.9726725335803613\n",
      "6\t0.999536822603057\n",
      "7\t0.9981472904122278\n",
      "8\t0.9958314034275128\n",
      "9\t1.0\n",
      "10\t0.9777777777777777\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 2  #################################################################\n",
      "Test subject: 02\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 206  10   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0 151  65   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 216 216 206 216 216 216  65 215]\n",
      "False Positive:  [  0   0   0   0   0   0  10   0 151   0   0]\n",
      "True Negative:  [2159 2159 2159 2159 2159 2159 2149 2159 2008 2159 2160]\n",
      "False Negative:  [  0   0   0   0   0  10   0   0   0 151   0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9322105263157895\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     0.954     0.976       216\n",
      "           6      0.956     1.000     0.977       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      0.589     1.000     0.741       216\n",
      "           9      1.000     0.301     0.463       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.932      2375\n",
      "   macro avg      0.959     0.932     0.923      2375\n",
      "weighted avg      0.959     0.932     0.923      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t0.9953682260305697\n",
      "7\t1.0\n",
      "8\t0.9300602130616026\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 3  #################################################################\n",
      "Test subject: 03\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 76 140   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   1   0   0   0 206   0   9   0   0   0]\n",
      " [  0   0   4   4  12  35 161   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0 215   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0  85   0   0  18   0 100  13   0]\n",
      " [  0   0   0   0   0   0   0   0  83   0 132]]\n",
      "\n",
      "\n",
      "True Positive:  [ 76 216 216 216 216 206 161 215 216  13 132]\n",
      "False Positive:  [  0 141   4  90  12  35  18   9 183   0   0]\n",
      "True Negative:  [2159 2018 2155 2069 2147 2124 2141 2150 1976 2159 2160]\n",
      "False Negative:  [140   0   0   0   0  10  55   1   0 203  83]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.7928421052631579\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.352     0.521       216\n",
      "           1      0.605     1.000     0.754       216\n",
      "           2      0.982     1.000     0.991       216\n",
      "           3      0.706     1.000     0.828       216\n",
      "           4      0.947     1.000     0.973       216\n",
      "           5      0.855     0.954     0.902       216\n",
      "           6      0.899     0.745     0.815       216\n",
      "           7      0.960     0.995     0.977       216\n",
      "           8      0.541     1.000     0.702       216\n",
      "           9      1.000     0.060     0.114       216\n",
      "          10      1.000     0.614     0.761       215\n",
      "\n",
      "    accuracy                          0.793      2375\n",
      "   macro avg      0.863     0.793     0.758      2375\n",
      "weighted avg      0.863     0.793     0.758      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t0.9346919870310328\n",
      "2\t0.9981472904122278\n",
      "3\t0.9583140342751274\n",
      "4\t0.9944418712366836\n",
      "5\t0.983788791106994\n",
      "6\t0.9916628068550255\n",
      "7\t0.9958314034275128\n",
      "8\t0.9152385363594256\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 4  #################################################################\n",
      "Test subject: 05\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   7 209   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 172   6  38   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  42 174   0]\n",
      " [  0   0   0   0   0   0   0  18   0 198   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 209 216 172 216 216  42 198 215]\n",
      "False Positive:  [  0   0   7   0   0   0   6  56   0 174   0]\n",
      "True Negative:  [2159 2159 2152 2159 2159 2159 2153 2103 2159 1985 2160]\n",
      "False Negative:  [  0   0   0   7   0  44   0   0 174  18   0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.8976842105263158\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      0.969     1.000     0.984       216\n",
      "           3      1.000     0.968     0.984       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     0.796     0.887       216\n",
      "           6      0.973     1.000     0.986       216\n",
      "           7      0.794     1.000     0.885       216\n",
      "           8      1.000     0.194     0.326       216\n",
      "           9      0.532     0.917     0.673       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.898      2375\n",
      "   macro avg      0.933     0.898     0.884      2375\n",
      "weighted avg      0.933     0.898     0.884      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t0.9967577582213988\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t0.9972209356183418\n",
      "7\t0.9740620657711904\n",
      "8\t1.0\n",
      "9\t0.9194071329319129\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 5  #################################################################\n",
      "Test subject: 08\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0  10 182   0   0  24   0   0   0   0]\n",
      " [  0   0   0   0 157  59   0   0   0   0   0]\n",
      " [  0   0   0   0   0 124   0   9   0  83   0]\n",
      " [  0   0   0   0   0   0 121   0   0  95   0]\n",
      " [  0   0   0   0   0   8   0 110   0  98   0]\n",
      " [  0   0   0   0   0   0   5   0 211   0   0]\n",
      " [  0   0   0   0   0  40   0   0   0 176   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0 214]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 182 157 124 121 110 211 176 214]\n",
      "False Positive:  [  0   0  10   0   0 107  30   9   0 276   0]\n",
      "True Negative:  [2159 2159 2149 2159 2159 2052 2129 2150 2159 1883 2160]\n",
      "False Negative:  [  0   0   0  34  59  92  95 106   5  40   1]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.8181052631578948\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      0.956     1.000     0.977       216\n",
      "           3      1.000     0.843     0.915       216\n",
      "           4      1.000     0.727     0.842       216\n",
      "           5      0.537     0.574     0.555       216\n",
      "           6      0.801     0.560     0.659       216\n",
      "           7      0.924     0.509     0.657       216\n",
      "           8      1.000     0.977     0.988       216\n",
      "           9      0.389     0.815     0.527       216\n",
      "          10      1.000     0.995     0.998       215\n",
      "\n",
      "    accuracy                          0.818      2375\n",
      "   macro avg      0.873     0.818     0.829      2375\n",
      "weighted avg      0.873     0.818     0.829      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t0.9953682260305697\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t0.9504400185270959\n",
      "6\t0.9861046780917091\n",
      "7\t0.9958314034275128\n",
      "8\t1.0\n",
      "9\t0.8721630384437239\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 6  #################################################################\n",
      "Test subject: 09\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 197   0   0   0  19]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 216 216 216 197 216 216 216 215]\n",
      "False Positive:  [ 0  0  0  0  0  0  0  0  0  0 19]\n",
      "True Negative:  [2159 2159 2159 2159 2159 2159 2159 2159 2159 2159 2141]\n",
      "False Negative:  [ 0  0  0  0  0  0 19  0  0  0  0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.992\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     1.000     1.000       216\n",
      "           6      1.000     0.912     0.954       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      1.000     1.000     1.000       216\n",
      "           9      1.000     1.000     1.000       216\n",
      "          10      0.919     1.000     0.958       215\n",
      "\n",
      "    accuracy                          0.992      2375\n",
      "   macro avg      0.993     0.992     0.992      2375\n",
      "weighted avg      0.993     0.992     0.992      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t1.0\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t1.0\n",
      "10\t0.9912037037037037\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 7  #################################################################\n",
      "Test subject: 10\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 215   1   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 214   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0 209   0   0   0   7   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 215 216 214 209 216 216 216 216 215]\n",
      "False Positive:  [0 0 0 1 0 2 0 0 0 7 0]\n",
      "True Negative:  [2159 2159 2159 2158 2159 2157 2159 2159 2159 2152 2160]\n",
      "False Negative:  [0 0 1 0 2 7 0 0 0 0 0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9957894736842106\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     0.995     0.998       216\n",
      "           3      0.995     1.000     0.998       216\n",
      "           4      1.000     0.991     0.995       216\n",
      "           5      0.991     0.968     0.979       216\n",
      "           6      1.000     1.000     1.000       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      1.000     1.000     1.000       216\n",
      "           9      0.969     1.000     0.984       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.996      2375\n",
      "   macro avg      0.996     0.996     0.996      2375\n",
      "weighted avg      0.996     0.996     0.996      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t0.999536822603057\n",
      "4\t1.0\n",
      "5\t0.999073645206114\n",
      "6\t1.0\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t0.9967577582213988\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 8  #################################################################\n",
      "Test subject: 11\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0  49 167   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 167 216 216 216 216 216 216 215]\n",
      "False Positive:  [ 0  0 49  0  0  0  0  0  0  0  0]\n",
      "True Negative:  [2159 2159 2110 2159 2159 2159 2159 2159 2159 2159 2160]\n",
      "False Negative:  [ 0  0  0 49  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9793684210526316\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      0.815     1.000     0.898       216\n",
      "           3      1.000     0.773     0.872       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     1.000     1.000       216\n",
      "           6      1.000     1.000     1.000       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      1.000     1.000     1.000       216\n",
      "           9      1.000     1.000     1.000       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.979      2375\n",
      "   macro avg      0.983     0.979     0.979      2375\n",
      "weighted avg      0.983     0.979     0.979      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t0.9773043075497916\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t1.0\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 9  #################################################################\n",
      "Test subject: 13\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 192   0   0   0   0   0   0   0  24]\n",
      " [  0   0   0 214   0   0   0   0   0   0   2]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1 154   0   0   0   0  61]\n",
      " [  0   0   0   0   0   0   0   0   0   0 216]\n",
      " [  0   0   0  30   0   0   0 186   0   0   0]\n",
      " [  0   0   0  69   0   0   0   0 147   0   0]\n",
      " [  0   0   0 193   0   0   0   0  11  12   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 192 214 216 154   0 186 147  12 215]\n",
      "False Positive:  [  0   0   0 292   1   0   0   0  11   0 303]\n",
      "True Negative:  [2159 2159 2159 1867 2158 2159 2159 2159 2148 2159 1857]\n",
      "False Negative:  [  0   0  24   2   0  62 216  30  69 204   0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.744421052631579\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     0.889     0.941       216\n",
      "           3      0.423     0.991     0.593       216\n",
      "           4      0.995     1.000     0.998       216\n",
      "           5      1.000     0.713     0.832       216\n",
      "           6      0.000     0.000     0.000       216\n",
      "           7      1.000     0.861     0.925       216\n",
      "           8      0.930     0.681     0.786       216\n",
      "           9      1.000     0.056     0.105       216\n",
      "          10      0.415     1.000     0.587       215\n",
      "\n",
      "    accuracy                          0.744      2375\n",
      "   macro avg      0.797     0.745     0.706      2375\n",
      "weighted avg      0.797     0.744     0.706      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t0.8647522000926354\n",
      "4\t0.999536822603057\n",
      "5\t1.0\n",
      "6\t1.0\n",
      "7\t1.0\n",
      "8\t0.9949050486336267\n",
      "9\t1.0\n",
      "10\t0.8597222222222223\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 10  #################################################################\n",
      "Test subject: 14\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 15 144   0   0   0   0   0  57   0   0   0]\n",
      " [  0   0 174  30  12   0   0   0   0   0   0]\n",
      " [  0   0  16 128   0   0  41   0   0  31   0]\n",
      " [  0   0   5   0 211   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0  67 149   0   0   0   0]\n",
      " [  0   0   0   0   0 121   0  95   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0  13   0   0   0 203   0]\n",
      " [  0   0   0   0   0   0  18   0  52  18 127]]\n",
      "\n",
      "\n",
      "True Positive:  [216 144 174 128 211 216 149  95 216 203 127]\n",
      "False Positive:  [ 15   0  21  30  12 201  59  57  52  49   0]\n",
      "True Negative:  [2144 2159 2138 2129 2147 1958 2100 2102 2107 2110 2160]\n",
      "False Negative:  [  0  72  42  88   5   0  67 121   0  13  88]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.7911578947368421\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.935     1.000     0.966       216\n",
      "           1      1.000     0.667     0.800       216\n",
      "           2      0.892     0.806     0.847       216\n",
      "           3      0.810     0.593     0.684       216\n",
      "           4      0.946     0.977     0.961       216\n",
      "           5      0.518     1.000     0.682       216\n",
      "           6      0.716     0.690     0.703       216\n",
      "           7      0.625     0.440     0.516       216\n",
      "           8      0.806     1.000     0.893       216\n",
      "           9      0.806     0.940     0.868       216\n",
      "          10      1.000     0.591     0.743       215\n",
      "\n",
      "    accuracy                          0.791      2375\n",
      "   macro avg      0.823     0.791     0.788      2375\n",
      "weighted avg      0.823     0.791     0.788      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t0.9930523390458545\n",
      "1\t1.0\n",
      "2\t0.9902732746641963\n",
      "3\t0.9861046780917091\n",
      "4\t0.9944418712366836\n",
      "5\t0.9069013432144511\n",
      "6\t0.9726725335803613\n",
      "7\t0.9735988883742474\n",
      "8\t0.9759147753589624\n",
      "9\t0.9773043075497916\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 11  #################################################################\n",
      "Test subject: 16\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0  11   0   0   1 204   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0  68   0 147]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 216 216 216 204 216 216 216 147]\n",
      "False Positive:  [ 0  0 11  0  0  1  0  0 68  0  0]\n",
      "True Negative:  [2159 2159 2148 2159 2159 2158 2159 2159 2091 2159 2160]\n",
      "False Negative:  [ 0  0  0  0  0  0 12  0  0  0 68]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9663157894736842\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      0.952     1.000     0.975       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      0.995     1.000     0.998       216\n",
      "           6      1.000     0.944     0.971       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      0.761     1.000     0.864       216\n",
      "           9      1.000     1.000     1.000       216\n",
      "          10      1.000     0.684     0.812       215\n",
      "\n",
      "    accuracy                          0.966      2375\n",
      "   macro avg      0.973     0.966     0.965      2375\n",
      "weighted avg      0.973     0.966     0.966      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t0.9949050486336267\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t0.999536822603057\n",
      "6\t1.0\n",
      "7\t1.0\n",
      "8\t0.968503937007874\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 12  #################################################################\n",
      "Test subject: 17\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[196  19   0   0   1   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 156  60   0   0   0   0   0]\n",
      " [ 28   0   0   0  24 128  24   0   0  12   0]\n",
      " [  0   0   0   0   0   0 181   0   0  35   0]\n",
      " [  0   0   0   0   0   0   0 121   0  95   0]\n",
      " [  0   0   0   0   0   0   0   0 193  23   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   3   0   0   0 212]]\n",
      "\n",
      "\n",
      "True Positive:  [196 216 216 216 156 128 181 121 193 216 212]\n",
      "False Positive:  [ 28  19   0   0  25  60  27   0   0 165   0]\n",
      "True Negative:  [2131 2140 2159 2159 2134 2099 2132 2159 2159 1994 2160]\n",
      "False Negative:  [20  0  0  0 60 88 35 95 23  0  3]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.863578947368421\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.875     0.907     0.891       216\n",
      "           1      0.919     1.000     0.958       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      0.862     0.722     0.786       216\n",
      "           5      0.681     0.593     0.634       216\n",
      "           6      0.870     0.838     0.854       216\n",
      "           7      1.000     0.560     0.718       216\n",
      "           8      1.000     0.894     0.944       216\n",
      "           9      0.567     1.000     0.724       216\n",
      "          10      1.000     0.986     0.993       215\n",
      "\n",
      "    accuracy                          0.864      2375\n",
      "   macro avg      0.889     0.864     0.864      2375\n",
      "weighted avg      0.888     0.864     0.864      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t0.9870310328855951\n",
      "1\t0.9911996294580825\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t0.9884205650764243\n",
      "5\t0.9722093561834182\n",
      "6\t0.9874942102825383\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t0.9235757295044001\n",
      "10\t1.0\n"
     ]
    }
   ],
   "source": [
    "accuracies = np.zeros((12))\n",
    "#accuraciesClass = np.zeros((12,11))\n",
    "precision = np.zeros((12,11))\n",
    "recall = np.zeros((12,11))\n",
    "fScore = np.zeros((12,11))\n",
    "support = np.zeros((12,11))\n",
    "specifities = np.zeros((12,11))\n",
    "\n",
    "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "measure = ['precision', 'recall', 'f1-score', 'support']\n",
    "\n",
    "for i in range(12):\n",
    "    print('##################################################################################################################################')\n",
    "    print('#####################################################  K-FOLD %d  #################################################################'%(i+1))\n",
    "    \n",
    "    subject_test = subjects[i]\n",
    "    print('Test subject: ' + str(subject_test))\n",
    "    \n",
    "    ##  GENERACIÓN DATASET\n",
    "    ts_seg = np.load('./augment_norm/subject_'+subject_test+'_seg.npy')\n",
    "    ts_lab = np.load('./augment_norm/subject_'+subject_test+'_lab.npy')\n",
    "    \n",
    "    limit = 40\n",
    "    ts_seg = ts_seg[:,:,:,:limit]\n",
    "    ####################################################################################################################\n",
    "    ## SHUFFLE DE DATOS\n",
    "    np.random.seed(235)\n",
    "    ts_seg = np.reshape(ts_seg[np.random.shuffle(np.arange(0,ts_seg.shape[0]))], (2375,1,128,limit))\n",
    "    ts_lab = np.reshape(ts_lab[np.random.shuffle(np.arange(0,ts_seg.shape[0]))], (2375,11))\n",
    "    \n",
    "    print('Test dataset: ')\n",
    "    print(ts_seg.shape, ts_lab.shape)\n",
    "    ####################################################################################################################\n",
    "    ## RED\n",
    "    model = load_model('./000_1_AUGNORMFFT_SP/CNN_'+subject_test+'.h5')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=learning_rate),metrics=['categorical_accuracy'])\n",
    "    ####################################################################################################################\n",
    "    ## TEST\n",
    "    predictions = model.predict(ts_seg, batch_size = batch_size, verbose = 0)\n",
    "    \n",
    "    y_pred = np.argmax(predictions,axis=-1)\n",
    "    y_pred = np.expand_dims(y_pred,axis=-1)\n",
    "    \n",
    "    y_true = np.argmax(ts_lab,axis=-1)\n",
    "    y_true = np.expand_dims(y_true,axis=-1)\n",
    "    \n",
    "    y_true_flat = np.ndarray.flatten(y_true)\n",
    "    y_pred_flat = np.ndarray.flatten(y_pred)\n",
    "    ####################################################################################################################\n",
    "    ## METRICS        \n",
    "    # CONFUSION MATRIX\n",
    "    print('\\n')\n",
    "    print('Confusion matrix:')\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    print('\\n')\n",
    "    tp, fp, tn, fn = perf_measure(cm)\n",
    "    tp, fp, tn, fn = np.asarray(tp), np.asarray(fp), np.asarray(tn), np.asarray(fn)\n",
    "    print('True Positive: ', str(tp))\n",
    "    print('False Positive: ', str(fp))\n",
    "    print('True Negative: ', str(tn))\n",
    "    print('False Negative: ', str(fn))\n",
    "    \n",
    "    # ACCURACY\n",
    "    print('\\n')\n",
    "    acc = metrics.accuracy_score(y_true_flat,y_pred_flat)\n",
    "    accuracies[i] = acc\n",
    "    print('Total accuracy: ')\n",
    "    print(acc)\n",
    "    '''\n",
    "    #accuraciesClass[i] = cm.diagonal()/cm.sum(axis=1)\n",
    "    accuraciesClass[i] = (tp+tn)/(tp+tn+fp+fn)\n",
    "    print('Accuracy per class: ')\n",
    "    for j in range(len(activities)):\n",
    "        print('%d'%(j)+'\\t'+ str(accuraciesClass[i,j]))\n",
    "    '''\n",
    "    # CLASSIFICATION REPORT\n",
    "    print('\\n')\n",
    "    print('Classification report:')\n",
    "    reportString = metrics.classification_report(y_true_flat, y_pred_flat, digits=3)\n",
    "    print(reportString)\n",
    "    report = metrics.classification_report(y_true_flat, y_pred_flat, digits=3, output_dict=True)\n",
    "    \n",
    "    for j in range(len(classes)):\n",
    "        precision[i,j] = report[classes[j]][measure[0]]\n",
    "        recall[i,j] = report[classes[j]][measure[1]]\n",
    "        fScore[i,j] = report[classes[j]][measure[2]]\n",
    "        support[i,j] = report[classes[j]][measure[3]]\n",
    "    \n",
    "    \n",
    "    # SPECIFITY\n",
    "    print('\\n')\n",
    "    print('Specifity: ')\n",
    "    specifity = tn/(tn+fp)\n",
    "    for j in range(len(activities)):\n",
    "        print('%d'%(j)+'\\t'+ str(specifity[j]))\n",
    "        specifities[i,j] = specifity[j]\n",
    "    \n",
    "    fo = open('./000_1_AUGNORMFFT_SP/metrics_'+subject_test+'.txt', \"w\")\n",
    "    fo.seek(0,2)\n",
    "    fo.write('Accuracy: ' + str(acc))\n",
    "    fo.write('\\n')\n",
    "    fo.write('Confusion matrix: ')\n",
    "    fo.write('\\n')\n",
    "    fo.write(str(cm))\n",
    "    fo.write('\\n')\n",
    "    fo.write('Specifity:')\n",
    "    fo.write(str(specifity))\n",
    "    fo.write('\\n')\n",
    "    fo.write('Report: ')\n",
    "    fo.write('\\n')\n",
    "    fo.write(reportString)\n",
    "    fo.close()\n",
    "    \n",
    "    \n",
    "    del subject_test, ts_seg, ts_lab, model, y_pred, y_true, predictions, y_true_flat, y_pred_flat, reportString, specifity, cm, report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.8935438596491229\n",
      "Precision per class: \n",
      "0\t0.9841720779220778\n",
      "1\t0.9603492460814113\n",
      "2\t0.9637603451524178\n",
      "3\t0.9111937951228795\n",
      "4\t0.9792355766639672\n",
      "5\t0.8631499591611921\n",
      "6\t0.8508083647558456\n",
      "7\t0.9404272504456328\n",
      "8\t0.8813312550427517\n",
      "9\t0.8552277625311882\n",
      "10\t0.9292793190131593\n",
      "Total precision: 0.9199031774447749\n",
      "Recall per class: \n",
      "0\t0.9382716049382717\n",
      "1\t0.9722222222222222\n",
      "2\t0.9741512345679012\n",
      "3\t0.9305555555555557\n",
      "4\t0.9513888888888887\n",
      "5\t0.8773148148148149\n",
      "6\t0.7847222222222223\n",
      "7\t0.8638117283950617\n",
      "8\t0.8769290123456791\n",
      "9\t0.753858024691358\n",
      "10\t0.9058139534883721\n",
      "Total recall: 0.8935490238300315\n",
      "F1-score per class: \n",
      "0\t0.948158332427892\n",
      "1\t0.9593165082055389\n",
      "2\t0.9675938112652748\n",
      "3\t0.9060609533241012\n",
      "4\t0.9629171025527651\n",
      "5\t0.8593940905415008\n",
      "6\t0.8133222540635464\n",
      "7\t0.8891532589381729\n",
      "8\t0.841557585454848\n",
      "9\t0.702980562935693\n",
      "10\t0.895849210473637\n",
      "Total F1-score: 0.88602760638027\n",
      "Specifities per class: \n",
      "0\t0.9983402809942875\n",
      "1\t0.9938243013740929\n",
      "2\t0.9960629921259841\n",
      "3\t0.9840589779218775\n",
      "4\t0.9980700941794041\n",
      "5\t0.9820518758684577\n",
      "6\t0.9941716844218003\n",
      "7\t0.9947892542843909\n",
      "8\t0.9817044928207502\n",
      "9\t0.9741006638876023\n",
      "10\t0.9857253086419754\n",
      "Total specifities: 0.9893545387746022\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "acc = np.sum(accuraciesClass,axis=0)/12\n",
    "print('Accuracy per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(acc[j]))\n",
    "print('Total accuracy: ' + str(sum(acc)/11))\n",
    "'''\n",
    "print('Total accuracy: ' + str(sum(accuracies)/12))\n",
    "\n",
    "prec = np.sum(precision,axis=0)/12\n",
    "print('Precision per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(prec[j]))\n",
    "print('Total precision: ' + str(sum(prec)/11))\n",
    "\n",
    "rec = np.sum(recall,axis=0)/12\n",
    "print('Recall per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(rec[j]))\n",
    "print('Total recall: ' + str(sum(rec)/11))\n",
    "\n",
    "fS = np.sum(fScore,axis=0)/12\n",
    "print('F1-score per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(fS[j]))\n",
    "print('Total F1-score: ' + str(sum(fS)/11))\n",
    "\n",
    "spec = np.sum(specifities,axis=0)/12\n",
    "print('Specifities per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(spec[j]))\n",
    "print('Total specifities: ' + str(sum(spec)/11))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
