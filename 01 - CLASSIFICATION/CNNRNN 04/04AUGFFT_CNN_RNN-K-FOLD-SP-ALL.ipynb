{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Módulos necesarios. Asegurarse de poder importarlos.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pylab import rcParams\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import os as os\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "from time import time\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\n",
      "3.6.8 (default, Aug 20 2019, 17:12:48) \n",
      "[GCC 8.3.0]\n",
      "sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12-FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects = ['01', '02', '03', '05', '08', '09', '10', '11', '13', '14', '16', '17']\n",
    "global activities\n",
    "activities = [9,10,11,12,13,19,20,21,24,25,31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ajustado a los datos\n",
    "n_time_steps = 128\n",
    "n_classes = 11 # Nº de clases (el 0 está eliminado)\n",
    "n_channels = 1 # Nº de canales\n",
    "n_columns = 40\n",
    "\n",
    "# Podríamos variarlo\n",
    "batch_size = 128 # Tamaño del batch\n",
    "learning_rate = 1e-3 # Learning rate (por defecto es 0.001)\n",
    "epochs = 100 # Épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LearningRateDecay:\n",
    "    def plot(self, epochs, title=\"Learning Rate Schedule\"):\n",
    "        # compute the set of learning rates for each corresponding\n",
    "        # epoch\n",
    "        lrs = [self(i) for i in epochs]\n",
    " \n",
    "        # the learning rate schedule\n",
    "        plt.style.use(\"ggplot\")\n",
    "        plt.figure()\n",
    "        plt.plot(epochs, lrs)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Epoch #\")\n",
    "        plt.ylabel(\"Learning Rate\")\n",
    "class StepDecay(LearningRateDecay):\n",
    "    def __init__(self, initAlpha=0.01, factor=0.25, dropEvery=10):\n",
    "        # store the base initial learning rate, drop factor, and\n",
    "        # epochs to drop every\n",
    "        self.initAlpha = initAlpha\n",
    "        self.factor = factor\n",
    "        self.dropEvery = dropEvery\n",
    " \n",
    "    def __call__(self, epoch):\n",
    "        # compute the learning rate for the current epoch\n",
    "        exp = np.floor((1 + epoch) / self.dropEvery)\n",
    "        alpha = self.initAlpha * (self.factor ** exp)\n",
    "        if(alpha<1e-9):\n",
    "            alpha=1e-9\n",
    "\n",
    "        # return the learning rate\n",
    "        return float(alpha) \n",
    "\n",
    "schedule = StepDecay(initAlpha=learning_rate, factor=0.4, dropEvery=10)\n",
    "\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(schedule, verbose = 1)\n",
    "callbacks_list = [reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualize training evolution\n",
    "def plot_curves(model, acc, loss, val_acc, val_loss, subject_test):\n",
    "    #########################################################################################\n",
    "    # LOSS plot\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(model.history.history[loss], label='Training loss')\n",
    "    plt.xlabel('Epochs', fontsize=15)\n",
    "    plt.ylabel('Loss', fontsize=15)\n",
    "    plt.tick_params(labelsize=10)\n",
    "    plt.legend(loc=1,prop={'size': 10})\n",
    "    plt.title('Loss in trainnig', fontsize=20)\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig('./04AUGFFT_SP_KFOLD_models/loss_train_04AUGFFT_SP_KFOLD_'+subject_test+'.pdf', bbox_inches='tight',format='pdf')\n",
    "    fig.savefig('./04AUGFFT_SP_KFOLD_models/loss_train_04AUGFFT_SP_KFOLD_'+subject_test+'svg', bbox_inches='tight',format='svg')\n",
    "    \n",
    "    #########################################################################################\n",
    "    # ACC plot\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(model.history.history[acc], label='Training accuracy')\n",
    "    plt.xlabel('Epochs', fontsize=15)\n",
    "    plt.ylabel('Accuracy', fontsize=15)\n",
    "    plt.tick_params(labelsize=10)\n",
    "    plt.legend(loc=1,prop={'size': 10})\n",
    "    plt.title('Accuracy in training', fontsize=20)\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig('./04AUGFFT_SP_KFOLD_models/acc_train_04AUGFFT_SP_KFOLD_'+subject_test+'pdf', bbox_inches='tight',format='pdf')\n",
    "    fig.savefig('./04AUGFFT_SP_KFOLD_models/acc_train_04AUGFFT_SP_KFOLD_'+subject_test+'svg', bbox_inches='tight',format='svg')\n",
    "    \n",
    "    #########################################################################################\n",
    "    # ACC+LOSS plot\n",
    "    plt.figure(figsize=(14,10))\n",
    "    plt_loss = host_subplot(111, axes_class=AA.Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "\n",
    "    plt_acc = plt_loss.twinx()\n",
    "    plt_acc.axis[\"right\"].toggle(all=True)\n",
    "    \n",
    "    plt_loss.set_xlim(0, len(model.history.history[loss]))\n",
    "    plt_loss.set_ylim(0, max(model.history.history[loss]))\n",
    "    plt_loss.set_xlabel('Epochs')\n",
    "    plt_loss.set_ylabel('Loss')\n",
    "    plt_acc.set_ylabel('Accuracy')\n",
    "                        \n",
    "    plt_loss.axis['left'].label.set_fontsize(15)\n",
    "    plt_loss.axis['bottom'].label.set_fontsize(15)\n",
    "    plt_acc.axis['right'].label.set_fontsize(15)\n",
    "    \n",
    "    plt_loss.plot(model.history.history[loss], c='tab:blue', ls='--', label='Training loss')\n",
    "    plt_acc.plot(model.history.history[acc], c='tab:orange',ls='--', label='Training accuracy')\n",
    "    \n",
    "    plt.tick_params(labelsize=10)\n",
    "    plt.title('Training performance', fontsize=20)\n",
    "    plt_acc.set_ylim(0, 1)\n",
    "    plt_loss.legend(loc=1, prop={'size': 10})\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig('./04AUGFFT_SP_KFOLD_models/all_train_04AUGFFT_SP_KFOLD_'+subject_test+'pdf', bbox_inches='tight',format='pdf')\n",
    "    fig.savefig('./04AUGFFT_SP_KFOLD_models/all_train_04AUGFFT_SP_KFOLD_'+subject_test+'svg', bbox_inches='tight',format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, subject_test, classes,\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(cm, xticklabels=classes, yticklabels=classes, square = True, robust = True, annot=True, cmap='YlOrBr')\n",
    "    plt.title('CONFUSION MATRIX')\n",
    "    plt.ylabel('TRUE ACTIVITY')\n",
    "    plt.xlabel('PREDICTION')\n",
    "    \n",
    "    locs, labels = plt.xticks()\n",
    "    plt.xticks(locs, labels, rotation='vertical')\n",
    "    locs, labels = plt.yticks()\n",
    "    plt.yticks(locs, labels, rotation='horizontal')\n",
    "\n",
    "    # Guardamos la imagen en formato vectorial\n",
    "    plt.draw()\n",
    "    plt.savefig('./04AUGFFT_SP_KFOLD_models/matriz_confusion_'+subject_test+'.svg', bbox_inches='tight',format='svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 1  ################################################################\n",
      "Training subjects: ['02', '03', '05', '08', '09', '10', '11', '13', '14', '16', '17']\n",
      "Test subject: 01\n",
      "Train dataset: \n",
      "(26125, 1, 128, 40) (26125, 11)\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2160 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity:  20\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2160 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity:  31\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 1, 128, 40)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 128, 40)       1088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 20)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64, 64, 20)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 20)        65600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 16, 5)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 16, 5)         256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 16, 5)         65600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 4, 2)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 4, 2)          0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 128)               98688     \n",
      "_________________________________________________________________\n",
      "activity_class (Dense)       (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 232,907\n",
      "Trainable params: 232,651\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 1/100\n",
      "26125/26125 [==============================] - 20s 771us/sample - loss: 0.6029 - categorical_accuracy: 0.7933\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 2/100\n",
      "26125/26125 [==============================] - 13s 498us/sample - loss: 0.0243 - categorical_accuracy: 0.9946\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 3/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 0.0159 - categorical_accuracy: 0.9958\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 4/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 0.0103 - categorical_accuracy: 0.9975\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 5/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 0.0088 - categorical_accuracy: 0.9974\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 6/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 0.0053 - categorical_accuracy: 0.9987\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 7/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 0.0126 - categorical_accuracy: 0.9958\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 8/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 0.0085 - categorical_accuracy: 0.9974\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 9/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 0.0014 - categorical_accuracy: 0.9998\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 10/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.8501e-04 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 11/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.4625e-04 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 12/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 3.9105e-04 - categorical_accuracy: 0.9998\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 13/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.4323e-04 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 14/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 2.5101e-04 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 15/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 1.4337e-04 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 16/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 4.4112e-04 - categorical_accuracy: 0.9998\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 17/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 3.0442e-04 - categorical_accuracy: 0.9999\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 18/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 2.3905e-04 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 19/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 0.0014 - categorical_accuracy: 0.9996\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.00016000000000000004.\n",
      "Epoch 20/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 5.9866e-04 - categorical_accuracy: 0.9999\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.00016000000000000004.\n",
      "Epoch 21/100\n",
      "26125/26125 [==============================] - 13s 494us/sample - loss: 6.6050e-04 - categorical_accuracy: 0.9997\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.00016000000000000004.\n",
      "Epoch 22/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 1.9442e-04 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.00016000000000000004.\n",
      "Epoch 23/100\n",
      "26125/26125 [==============================] - 13s 495us/sample - loss: 1.4316e-04 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.00016000000000000004.\n",
      "Epoch 24/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 8.8716e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.00016000000000000004.\n",
      "Epoch 25/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 8.5487e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.00016000000000000004.\n",
      "Epoch 26/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 6.5160e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.00016000000000000004.\n",
      "Epoch 27/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 5.8515e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.00016000000000000004.\n",
      "Epoch 28/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 6.0944e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00016000000000000004.\n",
      "Epoch 29/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 5.0815e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 6.400000000000001e-05.\n",
      "Epoch 30/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 5.3294e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 6.400000000000001e-05.\n",
      "Epoch 31/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 5.7172e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 6.400000000000001e-05.\n",
      "Epoch 32/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 4.8380e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 6.400000000000001e-05.\n",
      "Epoch 33/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 4.4722e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 6.400000000000001e-05.\n",
      "Epoch 34/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 4.5198e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 6.400000000000001e-05.\n",
      "Epoch 35/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 4.3558e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 6.400000000000001e-05.\n",
      "Epoch 36/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 4.4836e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 6.400000000000001e-05.\n",
      "Epoch 37/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 4.3952e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 6.400000000000001e-05.\n",
      "Epoch 38/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 5.6752e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 6.400000000000001e-05.\n",
      "Epoch 39/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 4.0015e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 2.5600000000000006e-05.\n",
      "Epoch 40/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 3.1707e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 2.5600000000000006e-05.\n",
      "Epoch 41/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.9934e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 2.5600000000000006e-05.\n",
      "Epoch 42/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 3.9750e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 2.5600000000000006e-05.\n",
      "Epoch 43/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 4.8924e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 2.5600000000000006e-05.\n",
      "Epoch 44/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 4.4155e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 2.5600000000000006e-05.\n",
      "Epoch 45/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 3.4694e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 2.5600000000000006e-05.\n",
      "Epoch 46/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 3.2741e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 2.5600000000000006e-05.\n",
      "Epoch 47/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 3.3385e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 2.5600000000000006e-05.\n",
      "Epoch 48/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.7912e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 2.5600000000000006e-05.\n",
      "Epoch 49/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 3.1196e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 1.0240000000000004e-05.\n",
      "Epoch 50/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.6744e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 1.0240000000000004e-05.\n",
      "Epoch 51/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.4008e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 1.0240000000000004e-05.\n",
      "Epoch 52/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 2.4182e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 1.0240000000000004e-05.\n",
      "Epoch 53/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 3.0285e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 1.0240000000000004e-05.\n",
      "Epoch 54/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 2.7988e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 1.0240000000000004e-05.\n",
      "Epoch 55/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.3743e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 1.0240000000000004e-05.\n",
      "Epoch 56/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.3949e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 1.0240000000000004e-05.\n",
      "Epoch 57/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.2050e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 1.0240000000000004e-05.\n",
      "Epoch 58/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 2.1698e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 1.0240000000000004e-05.\n",
      "Epoch 59/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.0761e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 4.096000000000002e-06.\n",
      "Epoch 60/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 1.9926e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 4.096000000000002e-06.\n",
      "Epoch 61/100\n",
      "26125/26125 [==============================] - 13s 497us/sample - loss: 2.6450e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 4.096000000000002e-06.\n",
      "Epoch 62/100\n",
      "26125/26125 [==============================] - 13s 496us/sample - loss: 2.0640e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 4.096000000000002e-06.\n",
      "Epoch 63/100\n",
      "26125/26125 [==============================] - 13s 498us/sample - loss: 2.0316e-05 - categorical_accuracy: 1.0000\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 4.096000000000002e-06.\n",
      "Epoch 64/100\n",
      "12928/26125 [=============>................] - ETA: 6s - loss: 1.9695e-05 - categorical_accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for i in range(12):\n",
    "    print('##################################################################################################################################')\n",
    "    print('#####################################################  K-FOLD %d  ################################################################'%(i+1))\n",
    "    \n",
    "    subject_test = subjects[i]\n",
    "    subjects_train = [s for s in subjects if s not in subject_test]\n",
    "    print('Training subjects: ' + str(subjects_train))\n",
    "    print('Test subject: ' + str(subject_test))\n",
    "    \n",
    "    ##  GENERACIÓN DATASET\n",
    "    tr_seg = np.concatenate((np.load('./augment_2/subject_'+subjects_train[0]+'_seg.npy'),np.load('./augment_2/subject_'+subjects_train[1]+'_seg.npy'),np.load('./augment_2/subject_'+subjects_train[2]+'_seg.npy'),np.load('./augment_2/subject_'+subjects_train[3]+'_seg.npy'),\n",
    "                             np.load('./augment_2/subject_'+subjects_train[4]+'_seg.npy'),np.load('./augment_2/subject_'+subjects_train[5]+'_seg.npy'),np.load('./augment_2/subject_'+subjects_train[6]+'_seg.npy'),np.load('./augment_2/subject_'+subjects_train[7]+'_seg.npy'),\n",
    "                             np.load('./augment_2/subject_'+subjects_train[8]+'_seg.npy'),np.load('./augment_2/subject_'+subjects_train[9]+'_seg.npy'),np.load('./augment_2/subject_'+subjects_train[10]+'_seg.npy')))\n",
    "    \n",
    "    tr_lab = np.concatenate((np.load('./augment_2/subject_'+subjects_train[0]+'_lab.npy'),np.load('./augment_2/subject_'+subjects_train[1]+'_lab.npy'),np.load('./augment_2/subject_'+subjects_train[2]+'_lab.npy'),np.load('./augment_2/subject_'+subjects_train[3]+'_lab.npy'),\n",
    "                             np.load('./augment_2/subject_'+subjects_train[4]+'_lab.npy'),np.load('./augment_2/subject_'+subjects_train[5]+'_lab.npy'),np.load('./augment_2/subject_'+subjects_train[6]+'_lab.npy'),np.load('./augment_2/subject_'+subjects_train[7]+'_lab.npy'),\n",
    "                             np.load('./augment_2/subject_'+subjects_train[8]+'_lab.npy'),np.load('./augment_2/subject_'+subjects_train[9]+'_lab.npy'),np.load('./augment_2/subject_'+subjects_train[10]+'_lab.npy')))\n",
    "\n",
    "    ts_seg = np.load('./augment_2/subject_'+subject_test+'_seg.npy')\n",
    "    ts_lab = np.load('./augment_2/subject_'+subject_test+'_lab.npy')\n",
    "    \n",
    "    limit = 40\n",
    "    tr_seg = tr_seg[:,:,:,:limit]\n",
    "    ts_seg = ts_seg[:,:,:,:limit]\n",
    "    ####################################################################################################################\n",
    "    ## SHUFFLE DE DATOS\n",
    "    np.random.seed(235)\n",
    "    tr_seg = np.reshape(tr_seg[np.random.shuffle(np.arange(0,tr_seg.shape[0]))], (11*2375,1,128,limit))\n",
    "    tr_lab = np.reshape(tr_lab[np.random.shuffle(np.arange(0,tr_seg.shape[0]))], (11*2375,11))\n",
    "\n",
    "    np.random.seed(235)\n",
    "    ts_seg = np.reshape(ts_seg[np.random.shuffle(np.arange(0,ts_seg.shape[0]))], (2375,1,128,limit))\n",
    "    ts_lab = np.reshape(ts_lab[np.random.shuffle(np.arange(0,ts_seg.shape[0]))], (2375,11))\n",
    "    \n",
    "    print('Train dataset: ')\n",
    "    print(tr_seg.shape, tr_lab.shape)\n",
    "    print('Test dataset: ')\n",
    "    print(ts_seg.shape, ts_lab.shape)\n",
    "    ####################################################################################################################\n",
    "    ## VISTA DE DFT-2D\n",
    "    plt.figure(figsize=(30,30))\n",
    "    plt.imshow(np.log(np.abs(np.fft.fftshift(tr_seg[0,0,:,20:40].T))**2))\n",
    "    plt.show()\n",
    "    print('Activity: ',activities[np.argmax(tr_lab[0])])\n",
    "\n",
    "    plt.figure(figsize=(30,30))\n",
    "    plt.imshow(np.log(np.fft.fftshift(tr_seg[10,0,:,20:40].T)**2))\n",
    "    plt.show()\n",
    "    print('Activity: ',activities[np.argmax(tr_lab[10])])\n",
    "    ####################################################################################################################\n",
    "    ## RED\n",
    "    quat_input = keras.Input(shape=(n_channels, n_time_steps, n_columns), name='input_layer')\n",
    "\n",
    "    # Some convolutional layers\n",
    "    conv_1 = keras.layers.Conv2D(64, kernel_size=4,padding='same',activation='relu', data_format = 'channels_first')(quat_input)\n",
    "    max_1 = keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same', data_format = 'channels_first')(conv_1)\n",
    "    bn_1 = keras.layers.BatchNormalization(axis=1)(max_1)\n",
    "    conv_2 = keras.layers.Conv2D(64,kernel_size=4, padding='same',activation='relu', data_format = 'channels_first')(bn_1)\n",
    "    max_2 = keras.layers.MaxPooling2D(pool_size=4, strides=4, padding='same', data_format = 'channels_first')(conv_2)\n",
    "    bn_2 = keras.layers.BatchNormalization(axis=1)(max_2)\n",
    "    conv_3 = keras.layers.Conv2D(64,kernel_size=4, padding='same',activation='relu', data_format = 'channels_first')(bn_2)\n",
    "    max_3 = keras.layers.MaxPooling2D(pool_size=4, strides=4, padding='same', data_format = 'channels_first')(conv_3)\n",
    "    bn_3 = keras.layers.BatchNormalization(axis=1)(max_3)\n",
    "\n",
    "    # Flatten the output of the convolutional layers\n",
    "    #conv_flat = keras.layers.Flatten()(max_3)\n",
    "    dr_1 = keras.layers.Dropout(0.5)(bn_3)\n",
    "\n",
    "    units = 128\n",
    "\n",
    "    res_1 = keras.layers.Reshape((4,units))(dr_1)\n",
    "\n",
    "    gru_1 = keras.layers.GRU(units, activation='tanh', return_sequences=False, reset_after = False)(res_1)\n",
    "    \n",
    "    # Output layers: separate outputs for the weather and the ground labels\n",
    "    multiclass_output = keras.layers.Dense(n_classes, activation='softmax',name='activity_class')(gru_1)\n",
    "    \n",
    "    # Creamos la estrcutura que contendrá a nuestro modelo\n",
    "    model = keras.Model(inputs=quat_input, outputs=[multiclass_output],name='cnn')\n",
    "\n",
    "    # Compilamos el modelo\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                  loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    ####################################################################################################################\n",
    "    ## TRAIN\n",
    "    history = model.fit(tr_seg,\n",
    "                        tr_lab,\n",
    "                        epochs = epochs,\n",
    "                        steps_per_epoch = None,\n",
    "                        verbose = 1,\n",
    "                        batch_size = batch_size,\n",
    "                        callbacks = callbacks_list)\n",
    "    model.save('./04AUGFFT_SP_KFOLD_models/CNN_'+subject_test+'.h5')\n",
    "    \n",
    "    #Visualize training evolution\n",
    "    plot_curves(model, 'categorical_accuracy', 'loss', 'val_categorical_accuracy', 'val_loss', subject_test)\n",
    "    ####################################################################################################################\n",
    "    ## TEST\n",
    "    predictions = model.predict(ts_seg, batch_size = batch_size, verbose = 1)\n",
    "    \n",
    "    print(predictions.shape)\n",
    "    \n",
    "    y_pred = np.argmax(predictions,axis=-1)\n",
    "    y_pred = np.expand_dims(y_pred,axis=-1)\n",
    "    print(y_pred[:100].T)\n",
    "    \n",
    "    y_true = np.argmax(ts_lab,axis=-1)\n",
    "    y_true = np.expand_dims(y_true,axis=-1)\n",
    "    print(y_true.shape)\n",
    "    print(y_true[:100].T)\n",
    "    \n",
    "    evaluation = model.evaluate(ts_seg, ts_lab, batch_size=batch_size, verbose=1)\n",
    "    accuracies.append(evaluation[1])\n",
    "    \n",
    "    fo = open('./04AUGFFT_SP_KFOLD_models/accuracy_'+subject_test+'.txt', \"w\")\n",
    "    fo.seek(0,2)\n",
    "    fo.write(str(evaluation))\n",
    "    fo.close()\n",
    "    \n",
    "    ####################################################################################################################\n",
    "    ## CONFUSION MATRIX\n",
    "    y_true_flat = np.ndarray.flatten(y_true)\n",
    "    y_pred_flat = np.ndarray.flatten(y_pred)\n",
    "    \n",
    "    plot_confusion_matrix(y_true_flat, y_pred_flat, subject_test, classes=activities)\n",
    "    \n",
    "    del subject_test, subjects_train, limit, tr_seg, tr_lab, ts_seg, ts_lab, model, history, y_pred, y_true, predictions, evaluation, y_true_flat, y_pred_flat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-Fold: 0.964947372674942\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for acc in accuracies:\n",
    "    sum += acc\n",
    "print('Accuracy of K-Fold: ' + str(sum/12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
