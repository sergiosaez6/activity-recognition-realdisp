{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos necesarios. Asegurarse de poder importarlos.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pylab import rcParams\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import os as os\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "from time import time\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\n",
      "3.6.8 (default, Aug 20 2019, 17:12:48) \n",
      "[GCC 8.3.0]\n",
      "sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12-FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['01', '02', '03', '05', '08', '09', '10', '11', '13', '14', '16', '17']\n",
    "global activities\n",
    "activities = [9,10,11,12,13,19,20,21,24,25,31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(cm1):\n",
    "    temp = 0\n",
    "    TruePositive = np.diag(cm1)\n",
    "    FalsePositive = []\n",
    "    for i in range(len(activities)):\n",
    "        FalsePositive.append(sum(cm1[:,i]) - cm1[i,i])\n",
    "    FalseNegative = []\n",
    "    for i in range(len(activities)):\n",
    "        FalseNegative.append(sum(cm1[i,:]) - cm1[i,i])\n",
    "    TrueNegative = []\n",
    "    for i in range(len(activities)):\n",
    "        temp = np.delete(cm1, i, 0)   # delete ith row\n",
    "        temp = np.delete(temp, i, 1)  # delete ith column\n",
    "        TrueNegative.append(sum(sum(temp)))\n",
    "    \n",
    "    return(TruePositive, FalsePositive, TrueNegative, FalseNegative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustado a los datos\n",
    "n_time_steps = 128\n",
    "n_classes = 11 # Nº de clases (el 0 está eliminado)\n",
    "n_channels = 1 # Nº de canales\n",
    "n_columns = 40\n",
    "\n",
    "# Podríamos variarlo\n",
    "batch_size = 128 # Tamaño del batch\n",
    "learning_rate = 1e-3 # Learning rate (por defecto es 0.001)\n",
    "epochs = 100 # Épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 1  #################################################################\n",
      "Test subject: 01\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 211   0   5   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0  46 170   0   0   0   0]\n",
      " [  0   0   0   0   0  34   0 182   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0  42 174   0]\n",
      " [  0   0   0   0   0   0   4   0   1   0 210]]\n",
      "\n",
      "\n",
      "True Positive:  [216 211 216 216 216 216 170 182 216 174 210]\n",
      "False Positive:  [ 0  0  0  5  0 80  4  0 43  0  0]\n",
      "True Negative:  [2159 2159 2159 2154 2159 2079 2155 2159 2116 2159 2160]\n",
      "False Negative:  [ 0  5  0  0  0  0 46 34  0 42  5]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9444210526315789\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     0.977     0.988       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      0.977     1.000     0.989       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      0.730     1.000     0.844       216\n",
      "           6      0.977     0.787     0.872       216\n",
      "           7      1.000     0.843     0.915       216\n",
      "           8      0.834     1.000     0.909       216\n",
      "           9      1.000     0.806     0.892       216\n",
      "          10      1.000     0.977     0.988       215\n",
      "\n",
      "    accuracy                          0.944      2375\n",
      "   macro avg      0.956     0.944     0.945      2375\n",
      "weighted avg      0.956     0.944     0.945      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t0.9976841130152848\n",
      "4\t1.0\n",
      "5\t0.9629458082445577\n",
      "6\t0.9981472904122278\n",
      "7\t1.0\n",
      "8\t0.9800833719314498\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 2  #################################################################\n",
      "Test subject: 02\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 188  28   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0  29   0   0   0   0 187   0   0]\n",
      " [  0   0   0   0   0   0   0   0 193  23   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 216 216 188 216 216 187  23 215]\n",
      "False Positive:  [  0   0   0  29   0   0  28   0 193   0   0]\n",
      "True Negative:  [2159 2159 2159 2130 2159 2159 2131 2159 1966 2159 2160]\n",
      "False Negative:  [  0   0   0   0   0  28   0   0  29 193   0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.8947368421052632\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      0.882     1.000     0.937       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     0.870     0.931       216\n",
      "           6      0.885     1.000     0.939       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      0.492     0.866     0.628       216\n",
      "           9      1.000     0.106     0.192       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.895      2375\n",
      "   macro avg      0.933     0.895     0.875      2375\n",
      "weighted avg      0.933     0.895     0.875      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t0.9865678554886521\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t0.9870310328855951\n",
      "7\t1.0\n",
      "8\t0.9106067623899954\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 3  #################################################################\n",
      "Test subject: 03\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 64 152   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 212   0   4   0   0   0]\n",
      " [  0  22   0  13   0  11 119  51   0   0   0]\n",
      " [  0   0   0   0   0   0  11 205   0   0   0]\n",
      " [  0   0   0   0   0   0  29   0 187   0   0]\n",
      " [  0   0   0  90   0   0  63   0  18  45   0]\n",
      " [  0   0   0   0   0   0   0   0  81   0 134]]\n",
      "\n",
      "\n",
      "True Positive:  [ 64 216 216 216 216 212 119 205 187  45 134]\n",
      "False Positive:  [  0 174   0 103   0  11 103  55  99   0   0]\n",
      "True Negative:  [2159 1985 2159 2056 2159 2148 2056 2104 2060 2159 2160]\n",
      "False Negative:  [152   0   0   0   0   4  97  11  29 171  81]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.7705263157894737\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.296     0.457       216\n",
      "           1      0.554     1.000     0.713       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      0.677     1.000     0.807       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      0.951     0.981     0.966       216\n",
      "           6      0.536     0.551     0.543       216\n",
      "           7      0.788     0.949     0.861       216\n",
      "           8      0.654     0.866     0.745       216\n",
      "           9      1.000     0.208     0.345       216\n",
      "          10      1.000     0.623     0.768       215\n",
      "\n",
      "    accuracy                          0.771      2375\n",
      "   macro avg      0.833     0.770     0.746      2375\n",
      "weighted avg      0.833     0.771     0.746      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t0.9194071329319129\n",
      "2\t1.0\n",
      "3\t0.952292728114868\n",
      "4\t1.0\n",
      "5\t0.9949050486336267\n",
      "6\t0.952292728114868\n",
      "7\t0.9745252431681334\n",
      "8\t0.9541454377026402\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 4  #################################################################\n",
      "Test subject: 05\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2 214   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 203  13   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 154  62   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 214 216 203 216 216 154 216 215]\n",
      "False Positive:  [ 0  0  2  0  0  0 13  0  0 62  0]\n",
      "True Negative:  [2159 2159 2157 2159 2159 2159 2146 2159 2159 2097 2160]\n",
      "False Negative:  [ 0  0  0  2  0 13  0  0 62  0  0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9675789473684211\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      0.991     1.000     0.995       216\n",
      "           3      1.000     0.991     0.995       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     0.940     0.969       216\n",
      "           6      0.943     1.000     0.971       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      1.000     0.713     0.832       216\n",
      "           9      0.777     1.000     0.874       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.968      2375\n",
      "   macro avg      0.974     0.968     0.967      2375\n",
      "weighted avg      0.974     0.968     0.967      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t0.999073645206114\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t0.9939786938397406\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t0.9712830013895322\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 5  #################################################################\n",
      "Test subject: 08\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 195  21   0   0   0   0   0   0   0]\n",
      " [  0   0  25 191   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 158  58   0   0   0   0   0]\n",
      " [  0   0   0   0   0 122   0  47   0  47   0]\n",
      " [  0   0  24   0   0   0 154   0   0  38   0]\n",
      " [  0   0   0   0   0   0   0 156   0  60   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0  40   0   0   0 176   0]\n",
      " [  0   0   0   0   0   0  70   0   0   0 145]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 195 191 158 122 154 156 216 176 145]\n",
      "False Positive:  [  0   0  49  21   0  98  70  47   0 145   0]\n",
      "True Negative:  [2159 2159 2110 2138 2159 2061 2089 2112 2159 2014 2160]\n",
      "False Negative:  [ 0  0 21 25 58 94 62 60  0 40 70]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.8189473684210526\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      0.799     0.903     0.848       216\n",
      "           3      0.901     0.884     0.893       216\n",
      "           4      1.000     0.731     0.845       216\n",
      "           5      0.555     0.565     0.560       216\n",
      "           6      0.688     0.713     0.700       216\n",
      "           7      0.768     0.722     0.745       216\n",
      "           8      1.000     1.000     1.000       216\n",
      "           9      0.548     0.815     0.655       216\n",
      "          10      1.000     0.674     0.806       215\n",
      "\n",
      "    accuracy                          0.819      2375\n",
      "   macro avg      0.842     0.819     0.823      2375\n",
      "weighted avg      0.842     0.819     0.823      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t0.9773043075497916\n",
      "3\t0.9902732746641963\n",
      "4\t1.0\n",
      "5\t0.9546086150995832\n",
      "6\t0.9675775822139879\n",
      "7\t0.9782306623436776\n",
      "8\t1.0\n",
      "9\t0.9328392774432608\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 6  #################################################################\n",
      "Test subject: 09\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 193   0   0   0  23   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   3   0   0   0 212]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 216 216 193 216 216 216 216 212]\n",
      "False Positive:  [ 0  0  0  0  0  0  3  0  0 23  0]\n",
      "True Negative:  [2159 2159 2159 2159 2159 2159 2156 2159 2159 2136 2160]\n",
      "False Negative:  [ 0  0  0  0  0 23  0  0  0  0  3]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9890526315789474\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     0.894     0.944       216\n",
      "           6      0.986     1.000     0.993       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      1.000     1.000     1.000       216\n",
      "           9      0.904     1.000     0.949       216\n",
      "          10      1.000     0.986     0.993       215\n",
      "\n",
      "    accuracy                          0.989      2375\n",
      "   macro avg      0.990     0.989     0.989      2375\n",
      "weighted avg      0.990     0.989     0.989      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t0.998610467809171\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t0.9893469198703103\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 7  #################################################################\n",
      "Test subject: 10\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 213   0   0   0   3   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 174   0   0   0  42]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 215   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 213 216 216 216 174 216 215 216 215]\n",
      "False Positive:  [ 0  0  0  0  0  0  3  0  0  0 43]\n",
      "True Negative:  [2159 2159 2159 2159 2159 2159 2156 2159 2159 2159 2117]\n",
      "False Negative:  [ 0  0  3  0  0  0 42  0  1  0  0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9806315789473684\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     0.986     0.993       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     1.000     1.000       216\n",
      "           6      0.983     0.806     0.885       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      1.000     0.995     0.998       216\n",
      "           9      1.000     1.000     1.000       216\n",
      "          10      0.833     1.000     0.909       215\n",
      "\n",
      "    accuracy                          0.981      2375\n",
      "   macro avg      0.983     0.981     0.980      2375\n",
      "weighted avg      0.983     0.981     0.981      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t0.998610467809171\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t1.0\n",
      "10\t0.9800925925925926\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 8  #################################################################\n",
      "Test subject: 11\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 50 166   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1 161   0   0  54   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   7   0 209   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 166 216 161 216 216 216 216 209 216 215]\n",
      "False Positive:  [50  0  1  0  0  0 61  0  0  0  0]\n",
      "True Negative:  [2109 2159 2158 2159 2159 2159 2098 2159 2159 2159 2160]\n",
      "False Negative:  [ 0 50  0 55  0  0  0  0  7  0  0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9528421052631579\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.812     1.000     0.896       216\n",
      "           1      1.000     0.769     0.869       216\n",
      "           2      0.995     1.000     0.998       216\n",
      "           3      1.000     0.745     0.854       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     1.000     1.000       216\n",
      "           6      0.780     1.000     0.876       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      1.000     0.968     0.984       216\n",
      "           9      1.000     1.000     1.000       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.953      2375\n",
      "   macro avg      0.962     0.953     0.952      2375\n",
      "weighted avg      0.962     0.953     0.952      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t0.9768411301528486\n",
      "1\t1.0\n",
      "2\t0.999536822603057\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t0.9717461787864752\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 9  #################################################################\n",
      "Test subject: 13\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 144  61   0   0   0   0   0   0  11]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   3  28   0   1   0   0 184]\n",
      " [  0   0   0   0   0   0   0   0   0   0 216]\n",
      " [  0   0   0  44   0   0   0 172   0   0   0]\n",
      " [  0   0   0 174   0   0   0   0  42   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 144 216 216  28   0 172  42   0 215]\n",
      "False Positive:  [  0   0   0 495   3   0   0   1   0   0 411]\n",
      "True Negative:  [2159 2159 2159 1664 2156 2159 2159 2158 2159 2159 1749]\n",
      "False Negative:  [  0   0  72   0   0 188 216  44 174 216   0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.6168421052631579\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     0.667     0.800       216\n",
      "           3      0.304     1.000     0.466       216\n",
      "           4      0.986     1.000     0.993       216\n",
      "           5      1.000     0.130     0.230       216\n",
      "           6      0.000     0.000     0.000       216\n",
      "           7      0.994     0.796     0.884       216\n",
      "           8      1.000     0.194     0.326       216\n",
      "           9      0.000     0.000     0.000       216\n",
      "          10      0.343     1.000     0.511       215\n",
      "\n",
      "    accuracy                          0.617      2375\n",
      "   macro avg      0.693     0.617     0.565      2375\n",
      "weighted avg      0.694     0.617     0.565      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t0.7707271885132005\n",
      "4\t0.998610467809171\n",
      "5\t1.0\n",
      "6\t1.0\n",
      "7\t0.999536822603057\n",
      "8\t1.0\n",
      "9\t1.0\n",
      "10\t0.8097222222222222\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 10  #################################################################\n",
      "Test subject: 14\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 214   0   0   0   1   1   0   0   0]\n",
      " [  0   0   0 132   0   0  84   0   0   0   0]\n",
      " [  0   0  23   0 193   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0 100   0 116   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0  44   0   0   0 172   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 214 132 193 216 216 116 216 172 215]\n",
      "False Positive:  [  0   0  23   0   0 144  85   1   0   0   0]\n",
      "True Negative:  [2159 2159 2136 2159 2159 2015 2074 2158 2159 2159 2160]\n",
      "False Negative:  [  0   0   2  84  23   0   0 100   0  44   0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.8934736842105263\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      0.903     0.991     0.945       216\n",
      "           3      1.000     0.611     0.759       216\n",
      "           4      1.000     0.894     0.944       216\n",
      "           5      0.600     1.000     0.750       216\n",
      "           6      0.718     1.000     0.836       216\n",
      "           7      0.991     0.537     0.697       216\n",
      "           8      1.000     1.000     1.000       216\n",
      "           9      1.000     0.796     0.887       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.893      2375\n",
      "   macro avg      0.928     0.894     0.892      2375\n",
      "weighted avg      0.928     0.893     0.892      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t0.9893469198703103\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t0.9333024548402038\n",
      "6\t0.9606299212598425\n",
      "7\t0.999536822603057\n",
      "8\t1.0\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 11  #################################################################\n",
      "Test subject: 16\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 137   0   0   0   0   0  79   0]\n",
      " [ 12   0   0   0 204   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0  89   0 126]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 137 204 216 216 216 216 216 126]\n",
      "False Positive:  [12  0  0  0  0  0  0  0 89 79  0]\n",
      "True Negative:  [2147 2159 2159 2159 2159 2159 2159 2159 2070 2080 2160]\n",
      "False Negative:  [ 0  0  0 79 12  0  0  0  0  0 89]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9242105263157895\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.947     1.000     0.973       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     0.634     0.776       216\n",
      "           4      1.000     0.944     0.971       216\n",
      "           5      1.000     1.000     1.000       216\n",
      "           6      1.000     1.000     1.000       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      0.708     1.000     0.829       216\n",
      "           9      0.732     1.000     0.845       216\n",
      "          10      1.000     0.586     0.739       215\n",
      "\n",
      "    accuracy                          0.924      2375\n",
      "   macro avg      0.944     0.924     0.921      2375\n",
      "weighted avg      0.944     0.924     0.921      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t0.9944418712366836\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t1.0\n",
      "7\t1.0\n",
      "8\t0.9587772116720704\n",
      "9\t0.9634089856415007\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 12  #################################################################\n",
      "Test subject: 17\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 174   0   0  42   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 134  73   5   0   4   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 203   0  13   0]\n",
      " [  0   0   0   0   0   0   0   0 204  12   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 174 216 216 216 134 216 203 204 216 215]\n",
      "False Positive:  [ 0  0  0  0 42  0 73  5  0 29  0]\n",
      "True Negative:  [2159 2159 2159 2159 2117 2159 2086 2154 2159 2130 2160]\n",
      "False Negative:  [ 0 42  0  0  0 82  0 13 12  0  0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9372631578947368\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     0.806     0.892       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      0.837     1.000     0.911       216\n",
      "           5      1.000     0.620     0.766       216\n",
      "           6      0.747     1.000     0.855       216\n",
      "           7      0.976     0.940     0.958       216\n",
      "           8      1.000     0.944     0.971       216\n",
      "           9      0.882     1.000     0.937       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.937      2375\n",
      "   macro avg      0.949     0.937     0.936      2375\n",
      "weighted avg      0.949     0.937     0.936      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t0.9805465493283928\n",
      "5\t1.0\n",
      "6\t0.9661880500231589\n",
      "7\t0.9976841130152848\n",
      "8\t1.0\n",
      "9\t0.9865678554886521\n",
      "10\t1.0\n"
     ]
    }
   ],
   "source": [
    "accuracies = np.zeros((12))\n",
    "#accuraciesClass = np.zeros((12,11))\n",
    "precision = np.zeros((12,11))\n",
    "recall = np.zeros((12,11))\n",
    "fScore = np.zeros((12,11))\n",
    "support = np.zeros((12,11))\n",
    "specifities = np.zeros((12,11))\n",
    "\n",
    "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "measure = ['precision', 'recall', 'f1-score', 'support']\n",
    "\n",
    "for i in range(12):\n",
    "    print('##################################################################################################################################')\n",
    "    print('#####################################################  K-FOLD %d  #################################################################'%(i+1))\n",
    "    \n",
    "    subject_test = subjects[i]\n",
    "    print('Test subject: ' + str(subject_test))\n",
    "    \n",
    "    ##  GENERACIÓN DATASET\n",
    "    ts_seg = np.load('./augment_2/subject_'+subject_test+'_seg.npy')\n",
    "    ts_lab = np.load('./augment_2/subject_'+subject_test+'_lab.npy')\n",
    "    \n",
    "    limit = 40\n",
    "    ts_seg = ts_seg[:,:,:,:limit]\n",
    "    ####################################################################################################################\n",
    "    ## SHUFFLE DE DATOS\n",
    "    np.random.seed(235)\n",
    "    ts_seg = np.reshape(ts_seg[np.random.shuffle(np.arange(0,ts_seg.shape[0]))], (2375,1,128,limit))\n",
    "    ts_lab = np.reshape(ts_lab[np.random.shuffle(np.arange(0,ts_seg.shape[0]))], (2375,11))\n",
    "    \n",
    "    print('Test dataset: ')\n",
    "    print(ts_seg.shape, ts_lab.shape)\n",
    "    ####################################################################################################################\n",
    "    ## RED\n",
    "    model = load_model('./000_1_AUGFFT_SP/CNN_'+subject_test+'.h5')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=learning_rate),metrics=['categorical_accuracy'])\n",
    "    ####################################################################################################################\n",
    "    ## TEST\n",
    "    predictions = model.predict(ts_seg, batch_size = batch_size, verbose = 0)\n",
    "    \n",
    "    y_pred = np.argmax(predictions,axis=-1)\n",
    "    y_pred = np.expand_dims(y_pred,axis=-1)\n",
    "    \n",
    "    y_true = np.argmax(ts_lab,axis=-1)\n",
    "    y_true = np.expand_dims(y_true,axis=-1)\n",
    "    \n",
    "    y_true_flat = np.ndarray.flatten(y_true)\n",
    "    y_pred_flat = np.ndarray.flatten(y_pred)\n",
    "    ####################################################################################################################\n",
    "    ## METRICS        \n",
    "    # CONFUSION MATRIX\n",
    "    print('\\n')\n",
    "    print('Confusion matrix:')\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    print('\\n')\n",
    "    tp, fp, tn, fn = perf_measure(cm)\n",
    "    tp, fp, tn, fn = np.asarray(tp), np.asarray(fp), np.asarray(tn), np.asarray(fn)\n",
    "    print('True Positive: ', str(tp))\n",
    "    print('False Positive: ', str(fp))\n",
    "    print('True Negative: ', str(tn))\n",
    "    print('False Negative: ', str(fn))\n",
    "    \n",
    "    # ACCURACY\n",
    "    print('\\n')\n",
    "    acc = metrics.accuracy_score(y_true_flat,y_pred_flat)\n",
    "    accuracies[i] = acc\n",
    "    print('Total accuracy: ')\n",
    "    print(acc)\n",
    "    '''\n",
    "    #accuraciesClass[i] = cm.diagonal()/cm.sum(axis=1)\n",
    "    accuraciesClass[i] = (tp+tn)/(tp+tn+fp+fn)\n",
    "    print('Accuracy per class: ')\n",
    "    for j in range(len(activities)):\n",
    "        print('%d'%(j)+'\\t'+ str(accuraciesClass[i,j]))\n",
    "    '''\n",
    "    # CLASSIFICATION REPORT\n",
    "    print('\\n')\n",
    "    print('Classification report:')\n",
    "    reportString = metrics.classification_report(y_true_flat, y_pred_flat, digits=3)\n",
    "    print(reportString)\n",
    "    report = metrics.classification_report(y_true_flat, y_pred_flat, digits=3, output_dict=True)\n",
    "    \n",
    "    for j in range(len(classes)):\n",
    "        precision[i,j] = report[classes[j]][measure[0]]\n",
    "        recall[i,j] = report[classes[j]][measure[1]]\n",
    "        fScore[i,j] = report[classes[j]][measure[2]]\n",
    "        support[i,j] = report[classes[j]][measure[3]]\n",
    "    \n",
    "    \n",
    "    # SPECIFITY\n",
    "    print('\\n')\n",
    "    print('Specifity: ')\n",
    "    specifity = tn/(tn+fp)\n",
    "    for j in range(len(activities)):\n",
    "        print('%d'%(j)+'\\t'+ str(specifity[j]))\n",
    "        specifities[i,j] = specifity[j]\n",
    "    \n",
    "    fo = open('./000_1_AUGFFT_SP/metrics_'+subject_test+'.txt', \"w\")\n",
    "    fo.seek(0,2)\n",
    "    fo.write('Accuracy: ' + str(acc))\n",
    "    fo.write('\\n')\n",
    "    fo.write('Confusion matrix: ')\n",
    "    fo.write('\\n')\n",
    "    fo.write(str(cm))\n",
    "    fo.write('\\n')\n",
    "    fo.write('Specifity:')\n",
    "    fo.write(str(specifity))\n",
    "    fo.write('\\n')\n",
    "    fo.write('Report: ')\n",
    "    fo.write('\\n')\n",
    "    fo.write(reportString)\n",
    "    fo.close()\n",
    "    \n",
    "    \n",
    "    del subject_test, ts_seg, ts_lab, model, y_pred, y_true, predictions, y_true_flat, y_pred_flat, reportString, specifity, cm, report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.8908771929824563\n",
      "Precision per class: \n",
      "0\t0.9799498746867168\n",
      "1\t0.9628205128205128\n",
      "2\t0.9740292756257718\n",
      "3\t0.8950720892261455\n",
      "4\t0.9852925560157163\n",
      "5\t0.9029123191679246\n",
      "6\t0.77026444179261\n",
      "7\t0.9598807189966\n",
      "8\t0.8906770810243633\n",
      "9\t0.8202388962413215\n",
      "10\t0.9313986510472133\n",
      "Total precision: 0.9156851287858996\n",
      "Recall per class: \n",
      "0\t0.941358024691358\n",
      "1\t0.9625771604938271\n",
      "2\t0.9621913580246914\n",
      "3\t0.9054783950617283\n",
      "4\t0.9641203703703703\n",
      "5\t0.8333333333333334\n",
      "6\t0.8213734567901234\n",
      "7\t0.8989197530864197\n",
      "8\t0.878858024691358\n",
      "9\t0.7276234567901234\n",
      "10\t0.9038759689922481\n",
      "Total recall: 0.8908826638477799\n",
      "F1-score per class: \n",
      "0\t0.9438651158568172\n",
      "1\t0.9552149437672374\n",
      "2\t0.9648939731867813\n",
      "3\t0.8729963286726856\n",
      "4\t0.9720507910031312\n",
      "5\t0.8298224202112907\n",
      "6\t0.7892494737794374\n",
      "7\t0.9215925088592195\n",
      "8\t0.8518197227099936\n",
      "9\t0.7148445203706107\n",
      "10\t0.8928386096455648\n",
      "Total F1-score: 0.8826534916420699\n",
      "Specifities per class: \n",
      "0\t0.9976069167824609\n",
      "1\t0.9932839277443261\n",
      "2\t0.9971051412691061\n",
      "3\t0.9747954299830169\n",
      "4\t0.9982630847614636\n",
      "5\t0.9871468272348309\n",
      "6\t0.9829010344295198\n",
      "7\t0.9957928053111008\n",
      "8\t0.9836343986413462\n",
      "9\t0.9869538366527711\n",
      "10\t0.9824845679012345\n",
      "Total specifities: 0.9890879973373798\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "acc = np.sum(accuraciesClass,axis=0)/12\n",
    "print('Accuracy per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(acc[j]))\n",
    "print('Total accuracy: ' + str(sum(acc)/11))\n",
    "'''\n",
    "print('Total accuracy: ' + str(sum(accuracies)/12))\n",
    "\n",
    "prec = np.sum(precision,axis=0)/12\n",
    "print('Precision per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(prec[j]))\n",
    "print('Total precision: ' + str(sum(prec)/11))\n",
    "\n",
    "rec = np.sum(recall,axis=0)/12\n",
    "print('Recall per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(rec[j]))\n",
    "print('Total recall: ' + str(sum(rec)/11))\n",
    "\n",
    "fS = np.sum(fScore,axis=0)/12\n",
    "print('F1-score per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(fS[j]))\n",
    "print('Total F1-score: ' + str(sum(fS)/11))\n",
    "\n",
    "spec = np.sum(specifities,axis=0)/12\n",
    "print('Specifities per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(spec[j]))\n",
    "print('Total specifities: ' + str(sum(spec)/11))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
