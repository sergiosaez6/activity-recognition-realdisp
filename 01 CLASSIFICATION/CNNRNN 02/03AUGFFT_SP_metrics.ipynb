{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos necesarios. Asegurarse de poder importarlos.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pylab import rcParams\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import os as os\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "from time import time\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\n",
      "3.6.8 (default, Aug 20 2019, 17:12:48) \n",
      "[GCC 8.3.0]\n",
      "sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12-FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['01', '02', '03', '05', '08', '09', '10', '11', '13', '14', '16', '17']\n",
    "global activities\n",
    "activities = [9,10,11,12,13,19,20,21,24,25,31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(cm1):\n",
    "    temp = 0\n",
    "    TruePositive = np.diag(cm1)\n",
    "    FalsePositive = []\n",
    "    for i in range(len(activities)):\n",
    "        FalsePositive.append(sum(cm1[:,i]) - cm1[i,i])\n",
    "    FalseNegative = []\n",
    "    for i in range(len(activities)):\n",
    "        FalseNegative.append(sum(cm1[i,:]) - cm1[i,i])\n",
    "    TrueNegative = []\n",
    "    for i in range(len(activities)):\n",
    "        temp = np.delete(cm1, i, 0)   # delete ith row\n",
    "        temp = np.delete(temp, i, 1)  # delete ith column\n",
    "        TrueNegative.append(sum(sum(temp)))\n",
    "    \n",
    "    return(TruePositive, FalsePositive, TrueNegative, FalseNegative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podríamos variarlo\n",
    "batch_size = 128 # Tamaño del batch\n",
    "learning_rate = 1e-3 # Learning rate (por defecto es 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 1  #################################################################\n",
      "Test subject: 01\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 196   0  20   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 215   0   1   0   0   0]\n",
      " [  0   0   0   0   0  91 105  20   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 179   0  37]\n",
      " [  0   0   0   0   0   0   0  30   0 186   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 196 216 216 216 215 105 216 179 186 215]\n",
      "False Positive:  [ 0  0  0 20  0 91  0 51  0  0 37]\n",
      "True Negative:  [2159 2159 2159 2139 2159 2068 2159 2108 2159 2159 2123]\n",
      "False Negative:  [  0  20   0   0   0   1 111   0  37  30   0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9162105263157895\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     0.907     0.951       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      0.915     1.000     0.956       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      0.703     0.995     0.824       216\n",
      "           6      1.000     0.486     0.654       216\n",
      "           7      0.809     1.000     0.894       216\n",
      "           8      1.000     0.829     0.906       216\n",
      "           9      1.000     0.861     0.925       216\n",
      "          10      0.853     1.000     0.921       215\n",
      "\n",
      "    accuracy                          0.916      2375\n",
      "   macro avg      0.935     0.916     0.912      2375\n",
      "weighted avg      0.935     0.916     0.912      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t0.9907364520611394\n",
      "4\t1.0\n",
      "5\t0.9578508568781844\n",
      "6\t1.0\n",
      "7\t0.9763779527559056\n",
      "8\t1.0\n",
      "9\t1.0\n",
      "10\t0.9828703703703704\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 2  #################################################################\n",
      "Test subject: 02\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 216 216 216 216 216 216   0 215]\n",
      "False Positive:  [  0   0   0   0   0   0   0   0 216   0   0]\n",
      "True Negative:  [2159 2159 2159 2159 2159 2159 2159 2159 1943 2159 2160]\n",
      "False Negative:  [  0   0   0   0   0   0   0   0   0 216   0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9090526315789473\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     1.000     1.000       216\n",
      "           6      1.000     1.000     1.000       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      0.500     1.000     0.667       216\n",
      "           9      0.000     0.000     0.000       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.909      2375\n",
      "   macro avg      0.864     0.909     0.879      2375\n",
      "weighted avg      0.864     0.909     0.879      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t1.0\n",
      "7\t1.0\n",
      "8\t0.8999536822603057\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 3  #################################################################\n",
      "Test subject: 03\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 213   0   0   0   0   0   3   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 215   0   1]\n",
      " [  0   0   0   3   0   0   0   0 148  65   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0 214]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 213 216 216 216 216 215  65 214]\n",
      "False Positive:  [  0   0   0   3   0   0   0   0 149   3   1]\n",
      "True Negative:  [2159 2159 2159 2156 2159 2159 2159 2159 2010 2156 2159]\n",
      "False Negative:  [  0   0   0   3   0   0   0   0   1 151   1]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9343157894736842\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      0.986     0.986     0.986       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     1.000     1.000       216\n",
      "           6      1.000     1.000     1.000       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      0.591     0.995     0.741       216\n",
      "           9      0.956     0.301     0.458       216\n",
      "          10      0.995     0.995     0.995       215\n",
      "\n",
      "    accuracy                          0.934      2375\n",
      "   macro avg      0.957     0.934     0.926      2375\n",
      "weighted avg      0.957     0.934     0.925      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t0.998610467809171\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t1.0\n",
      "7\t1.0\n",
      "8\t0.9309865678554886\n",
      "9\t0.998610467809171\n",
      "10\t0.999537037037037\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 4  #################################################################\n",
      "Test subject: 05\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 207   9   0   0   0   0]\n",
      " [  0   0   0  10   0   0 206   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 189  27   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 216 216 207 206 216 189 216 215]\n",
      "False Positive:  [ 0  0  0 10  0  0  9  0  0 27  0]\n",
      "True Negative:  [2159 2159 2159 2149 2159 2159 2150 2159 2159 2132 2160]\n",
      "False Negative:  [ 0  0  0  0  0  9 10  0 27  0  0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9806315789473684\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      0.956     1.000     0.977       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     0.958     0.979       216\n",
      "           6      0.958     0.954     0.956       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      1.000     0.875     0.933       216\n",
      "           9      0.889     1.000     0.941       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.981      2375\n",
      "   macro avg      0.982     0.981     0.981      2375\n",
      "weighted avg      0.982     0.981     0.981      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t0.9953682260305697\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t0.9958314034275128\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t0.9874942102825383\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 5  #################################################################\n",
      "Test subject: 08\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0  11 202   0   0   3   0   0   0   0]\n",
      " [  0   0   0   0 112 104   0   0   0   0   0]\n",
      " [  0   0   0   0   0 215   0   0   0   1   0]\n",
      " [  0   0   0  61   0   0 155   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 158   0  58   0]\n",
      " [  0   0   0   0   0   0   0   0 140   0  76]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 202 112 215 155 158 140 216 215]\n",
      "False Positive:  [  0   0  11  61   0 104   3   0   0  59  76]\n",
      "True Negative:  [2159 2159 2148 2098 2159 2055 2156 2159 2159 2100 2084]\n",
      "False Negative:  [  0   0   0  14 104   1  61  58  76   0   0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.8677894736842106\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      0.952     1.000     0.975       216\n",
      "           3      0.768     0.935     0.843       216\n",
      "           4      1.000     0.519     0.683       216\n",
      "           5      0.674     0.995     0.804       216\n",
      "           6      0.981     0.718     0.829       216\n",
      "           7      1.000     0.731     0.845       216\n",
      "           8      1.000     0.648     0.787       216\n",
      "           9      0.785     1.000     0.880       216\n",
      "          10      0.739     1.000     0.850       215\n",
      "\n",
      "    accuracy                          0.868      2375\n",
      "   macro avg      0.900     0.868     0.863      2375\n",
      "weighted avg      0.900     0.868     0.863      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t0.9949050486336267\n",
      "3\t0.9717461787864752\n",
      "4\t1.0\n",
      "5\t0.951829550717925\n",
      "6\t0.998610467809171\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t0.9726725335803613\n",
      "10\t0.9648148148148148\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 6  #################################################################\n",
      "Test subject: 09\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0  40 176   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   7   0   0   0 208]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 176 216 216 216 216 216 216 208]\n",
      "False Positive:  [ 0  0 40  0  0  0  7  0  0  0  0]\n",
      "True Negative:  [2159 2159 2119 2159 2159 2159 2152 2159 2159 2159 2160]\n",
      "False Negative:  [ 0  0  0 40  0  0  0  0  0  0  7]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9802105263157894\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      0.844     1.000     0.915       216\n",
      "           3      1.000     0.815     0.898       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     1.000     1.000       216\n",
      "           6      0.969     1.000     0.984       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      1.000     1.000     1.000       216\n",
      "           9      1.000     1.000     1.000       216\n",
      "          10      1.000     0.967     0.983       215\n",
      "\n",
      "    accuracy                          0.980      2375\n",
      "   macro avg      0.983     0.980     0.980      2375\n",
      "weighted avg      0.983     0.980     0.980      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t0.9814729041222788\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t0.9967577582213988\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 7  #################################################################\n",
      "Test subject: 10\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 216 216 216 216 216 216 216 215]\n",
      "False Positive:  [0 0 0 0 0 0 0 0 0 0 0]\n",
      "True Negative:  [2159 2159 2159 2159 2159 2159 2159 2159 2159 2159 2160]\n",
      "False Negative:  [0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "1.0\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     1.000     1.000       216\n",
      "           6      1.000     1.000     1.000       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      1.000     1.000     1.000       216\n",
      "           9      1.000     1.000     1.000       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          1.000      2375\n",
      "   macro avg      1.000     1.000     1.000      2375\n",
      "weighted avg      1.000     1.000     1.000      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t1.0\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 8  #################################################################\n",
      "Test subject: 11\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 194   0   0  22   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 194 216 216 216 216 216 216 215]\n",
      "False Positive:  [ 0  0  0  0  0  0 22  0  0  0  0]\n",
      "True Negative:  [2159 2159 2159 2159 2159 2159 2137 2159 2159 2159 2160]\n",
      "False Negative:  [ 0  0  0 22  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9907368421052631\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     0.898     0.946       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     1.000     1.000       216\n",
      "           6      0.908     1.000     0.952       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      1.000     1.000     1.000       216\n",
      "           9      1.000     1.000     1.000       216\n",
      "          10      1.000     1.000     1.000       215\n",
      "\n",
      "    accuracy                          0.991      2375\n",
      "   macro avg      0.992     0.991     0.991      2375\n",
      "weighted avg      0.992     0.991     0.991      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t0.9898100972672533\n",
      "7\t1.0\n",
      "8\t1.0\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 9  #################################################################\n",
      "Test subject: 13\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 212   4   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [ 61   0   0   0   0 128   0  17   0  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 216]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 212 216 216 128   0 216 216 216 215]\n",
      "False Positive:  [ 61   0   0   4   0   0   0  17   0  10 216]\n",
      "True Negative:  [2098 2159 2159 2155 2159 2159 2159 2142 2159 2149 1944]\n",
      "False Negative:  [  0   0   4   0   0  88 216   0   0   0   0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.8703157894736843\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.780     1.000     0.876       216\n",
      "           1      1.000     1.000     1.000       216\n",
      "           2      1.000     0.981     0.991       216\n",
      "           3      0.982     1.000     0.991       216\n",
      "           4      1.000     1.000     1.000       216\n",
      "           5      1.000     0.593     0.744       216\n",
      "           6      0.000     0.000     0.000       216\n",
      "           7      0.927     1.000     0.962       216\n",
      "           8      1.000     1.000     1.000       216\n",
      "           9      0.956     1.000     0.977       216\n",
      "          10      0.499     1.000     0.666       215\n",
      "\n",
      "    accuracy                          0.870      2375\n",
      "   macro avg      0.831     0.870     0.837      2375\n",
      "weighted avg      0.831     0.870     0.837      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t0.9717461787864752\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t0.9981472904122278\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t1.0\n",
      "7\t0.9921259842519685\n",
      "8\t1.0\n",
      "9\t0.9953682260305697\n",
      "10\t0.9\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 10  #################################################################\n",
      "Test subject: 14\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [149  67   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  83   0   0 133   0   0   0   0]\n",
      " [  0   0   5   0 211   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0 213   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 211   0   5]\n",
      " [  0   0   0   0   0  13   0   0   0 203   0]\n",
      " [  0   0   0   0   0   0   0   0  21   0 194]]\n",
      "\n",
      "\n",
      "True Positive:  [216  67 216  83 211 216 216 213 211 203 194]\n",
      "False Positive:  [149   0   5   0   0  16 133   0  21   0   5]\n",
      "True Negative:  [2010 2159 2154 2159 2159 2143 2026 2159 2138 2159 2155]\n",
      "False Negative:  [  0 149   0 133   5   0   0   3   5  13  21]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.8614736842105263\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.592     1.000     0.744       216\n",
      "           1      1.000     0.310     0.473       216\n",
      "           2      0.977     1.000     0.989       216\n",
      "           3      1.000     0.384     0.555       216\n",
      "           4      1.000     0.977     0.988       216\n",
      "           5      0.931     1.000     0.964       216\n",
      "           6      0.619     1.000     0.765       216\n",
      "           7      1.000     0.986     0.993       216\n",
      "           8      0.909     0.977     0.942       216\n",
      "           9      1.000     0.940     0.969       216\n",
      "          10      0.975     0.902     0.937       215\n",
      "\n",
      "    accuracy                          0.861      2375\n",
      "   macro avg      0.909     0.861     0.847      2375\n",
      "weighted avg      0.909     0.861     0.847      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t0.9309865678554886\n",
      "1\t1.0\n",
      "2\t0.9976841130152848\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t0.9925891616489115\n",
      "6\t0.9383974062065771\n",
      "7\t1.0\n",
      "8\t0.9902732746641963\n",
      "9\t1.0\n",
      "10\t0.9976851851851852\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 11  #################################################################\n",
      "Test subject: 16\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 216   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   5   0   0 211   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 216   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 216   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0  76   0 139]]\n",
      "\n",
      "\n",
      "True Positive:  [216 216 216 216 211 216 216 216 216 216 139]\n",
      "False Positive:  [ 0  5  0  0  0  0  0  0 76  0  0]\n",
      "True Negative:  [2159 2154 2159 2159 2159 2159 2159 2159 2083 2159 2160]\n",
      "False Negative:  [ 0  0  0  0  5  0  0  0  0  0 76]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9658947368421053\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      0.977     1.000     0.989       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      1.000     0.977     0.988       216\n",
      "           5      1.000     1.000     1.000       216\n",
      "           6      1.000     1.000     1.000       216\n",
      "           7      1.000     1.000     1.000       216\n",
      "           8      0.740     1.000     0.850       216\n",
      "           9      1.000     1.000     1.000       216\n",
      "          10      1.000     0.647     0.785       215\n",
      "\n",
      "    accuracy                          0.966      2375\n",
      "   macro avg      0.974     0.966     0.965      2375\n",
      "weighted avg      0.974     0.966     0.965      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t0.9976841130152848\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t1.0\n",
      "5\t1.0\n",
      "6\t1.0\n",
      "7\t1.0\n",
      "8\t0.9647985178323297\n",
      "9\t1.0\n",
      "10\t1.0\n",
      "##################################################################################################################################\n",
      "#####################################################  K-FOLD 12  #################################################################\n",
      "Test subject: 17\n",
      "Test dataset: \n",
      "(2375, 1, 128, 40) (2375, 11)\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[216   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 186   0   0  30   0   0   0   0   0   0]\n",
      " [  0   0 216   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 216   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 216   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 115  19  82   0   0   0]\n",
      " [  0   0   0   0   0   0 216   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 216   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 215   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0 216   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 215]]\n",
      "\n",
      "\n",
      "True Positive:  [216 186 216 216 216 115 216 216 215 216 215]\n",
      "False Positive:  [ 0  0  0  0 30  0 19 82  0  0  1]\n",
      "True Negative:  [2159 2159 2159 2159 2129 2159 2140 2077 2159 2159 2159]\n",
      "False Negative:  [  0  30   0   0   0 101   0   0   1   0   0]\n",
      "\n",
      "\n",
      "Total accuracy: \n",
      "0.9444210526315789\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       216\n",
      "           1      1.000     0.861     0.925       216\n",
      "           2      1.000     1.000     1.000       216\n",
      "           3      1.000     1.000     1.000       216\n",
      "           4      0.878     1.000     0.935       216\n",
      "           5      1.000     0.532     0.695       216\n",
      "           6      0.919     1.000     0.958       216\n",
      "           7      0.725     1.000     0.840       216\n",
      "           8      1.000     0.995     0.998       216\n",
      "           9      1.000     1.000     1.000       216\n",
      "          10      0.995     1.000     0.998       215\n",
      "\n",
      "    accuracy                          0.944      2375\n",
      "   macro avg      0.956     0.944     0.941      2375\n",
      "weighted avg      0.956     0.944     0.941      2375\n",
      "\n",
      "\n",
      "\n",
      "Specifity: \n",
      "0\t1.0\n",
      "1\t1.0\n",
      "2\t1.0\n",
      "3\t1.0\n",
      "4\t0.9861046780917091\n",
      "5\t1.0\n",
      "6\t0.9911996294580825\n",
      "7\t0.9620194534506716\n",
      "8\t1.0\n",
      "9\t1.0\n",
      "10\t0.999537037037037\n"
     ]
    }
   ],
   "source": [
    "accuracies = np.zeros((12))\n",
    "#accuraciesClass = np.zeros((12,11))\n",
    "precision = np.zeros((12,11))\n",
    "recall = np.zeros((12,11))\n",
    "fScore = np.zeros((12,11))\n",
    "support = np.zeros((12,11))\n",
    "specifities = np.zeros((12,11))\n",
    "\n",
    "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "measure = ['precision', 'recall', 'f1-score', 'support']\n",
    "\n",
    "for i in range(12):\n",
    "    print('##################################################################################################################################')\n",
    "    print('#####################################################  K-FOLD %d  #################################################################'%(i+1))\n",
    "    \n",
    "    subject_test = subjects[i]\n",
    "    print('Test subject: ' + str(subject_test))\n",
    "    \n",
    "    ##  GENERACIÓN DATASET\n",
    "    ts_seg = np.load('./augment_2/subject_'+subject_test+'_seg.npy')\n",
    "    ts_lab = np.load('./augment_2/subject_'+subject_test+'_lab.npy')\n",
    "    \n",
    "    limit = 40\n",
    "    ts_seg = ts_seg[:,:,:,:limit]\n",
    "    ####################################################################################################################\n",
    "    ## SHUFFLE DE DATOS\n",
    "    np.random.seed(235)\n",
    "    ts_seg = np.reshape(ts_seg[np.random.shuffle(np.arange(0,ts_seg.shape[0]))], (2375,1,128,limit))\n",
    "    ts_lab = np.reshape(ts_lab[np.random.shuffle(np.arange(0,ts_seg.shape[0]))], (2375,11))\n",
    "    \n",
    "    print('Test dataset: ')\n",
    "    print(ts_seg.shape, ts_lab.shape)\n",
    "    ####################################################################################################################\n",
    "    ## RED\n",
    "    model = load_model('./03AUGFFT_SP_KFOLD_models/CNN_RNN_'+subject_test+'.h5')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=learning_rate),metrics=['categorical_accuracy'])\n",
    "    ####################################################################################################################\n",
    "    ## TEST\n",
    "    predictions = model.predict(ts_seg, batch_size = batch_size, verbose = 0)\n",
    "    \n",
    "    y_pred = np.argmax(predictions,axis=-1)\n",
    "    y_pred = np.expand_dims(y_pred,axis=-1)\n",
    "    \n",
    "    y_true = np.argmax(ts_lab,axis=-1)\n",
    "    y_true = np.expand_dims(y_true,axis=-1)\n",
    "    \n",
    "    y_true_flat = np.ndarray.flatten(y_true)\n",
    "    y_pred_flat = np.ndarray.flatten(y_pred)\n",
    "    ####################################################################################################################\n",
    "    ## METRICS        \n",
    "    # CONFUSION MATRIX\n",
    "    print('\\n')\n",
    "    print('Confusion matrix:')\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    print('\\n')\n",
    "    tp, fp, tn, fn = perf_measure(cm)\n",
    "    tp, fp, tn, fn = np.asarray(tp), np.asarray(fp), np.asarray(tn), np.asarray(fn)\n",
    "    print('True Positive: ', str(tp))\n",
    "    print('False Positive: ', str(fp))\n",
    "    print('True Negative: ', str(tn))\n",
    "    print('False Negative: ', str(fn))\n",
    "    \n",
    "    # ACCURACY\n",
    "    print('\\n')\n",
    "    acc = metrics.accuracy_score(y_true_flat,y_pred_flat)\n",
    "    accuracies[i] = acc\n",
    "    print('Total accuracy: ')\n",
    "    print(acc)\n",
    "    '''\n",
    "    #accuraciesClass[i] = cm.diagonal()/cm.sum(axis=1)\n",
    "    accuraciesClass[i] = (tp+tn)/(tp+tn+fp+fn)\n",
    "    print('Accuracy per class: ')\n",
    "    for j in range(len(activities)):\n",
    "        print('%d'%(j)+'\\t'+ str(accuraciesClass[i,j]))\n",
    "    '''\n",
    "    # CLASSIFICATION REPORT\n",
    "    print('\\n')\n",
    "    print('Classification report:')\n",
    "    reportString = metrics.classification_report(y_true_flat, y_pred_flat, digits=3)\n",
    "    print(reportString)\n",
    "    report = metrics.classification_report(y_true_flat, y_pred_flat, digits=3, output_dict=True)\n",
    "    \n",
    "    for j in range(len(classes)):\n",
    "        precision[i,j] = report[classes[j]][measure[0]]\n",
    "        recall[i,j] = report[classes[j]][measure[1]]\n",
    "        fScore[i,j] = report[classes[j]][measure[2]]\n",
    "        support[i,j] = report[classes[j]][measure[3]]\n",
    "    \n",
    "    \n",
    "    # SPECIFITY\n",
    "    print('\\n')\n",
    "    print('Specifity: ')\n",
    "    specifity = tn/(tn+fp)\n",
    "    for j in range(len(activities)):\n",
    "        print('%d'%(j)+'\\t'+ str(specifity[j]))\n",
    "        specifities[i,j] = specifity[j]\n",
    "    \n",
    "    fo = open('./03AUGFFT_SP_KFOLD_models/metrics_'+subject_test+'.txt', \"w\")\n",
    "    fo.seek(0,2)\n",
    "    fo.write('Accuracy: ' + str(acc))\n",
    "    fo.write('\\n')\n",
    "    fo.write('Confusion matrix: ')\n",
    "    fo.write('\\n')\n",
    "    fo.write(str(cm))\n",
    "    fo.write('\\n')\n",
    "    fo.write('Specifity:')\n",
    "    fo.write(str(specifity))\n",
    "    fo.write('\\n')\n",
    "    fo.write('Report: ')\n",
    "    fo.write('\\n')\n",
    "    fo.write(reportString)\n",
    "    fo.close()\n",
    "    \n",
    "    \n",
    "    del subject_test, ts_seg, ts_lab, model, y_pred, y_true, predictions, y_true_flat, y_pred_flat, reportString, specifity, cm, report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.9350877192982457\n",
      "Precision per class: \n",
      "0\t0.9476303512849679\n",
      "1\t0.9981146304675717\n",
      "2\t0.981055617985927\n",
      "3\t0.9672497149257259\n",
      "4\t0.9898373983739838\n",
      "5\t0.9423025044221799\n",
      "6\t0.8627820995623182\n",
      "7\t0.9550716337849572\n",
      "8\t0.894989010556441\n",
      "9\t0.8821648333061659\n",
      "10\t0.9213699754105352\n",
      "Total precision: 0.9402334336437068\n",
      "Recall per class: \n",
      "0\t1.0\n",
      "1\t0.9232253086419754\n",
      "2\t0.9984567901234568\n",
      "3\t0.91820987654321\n",
      "4\t0.9560185185185185\n",
      "5\t0.9228395061728397\n",
      "6\t0.8464506172839507\n",
      "7\t0.976466049382716\n",
      "8\t0.9432870370370369\n",
      "9\t0.8418209876543209\n",
      "10\t0.9593023255813953\n",
      "Total recall: 0.9350979106308565\n",
      "F1-score per class: \n",
      "0\t0.9683177799578493\n",
      "1\t0.9449071692188554\n",
      "2\t0.9891363412936743\n",
      "3\t0.9294144141953006\n",
      "4\t0.9662143800488464\n",
      "5\t0.9174626933683391\n",
      "6\t0.8414223977394601\n",
      "7\t0.9612451439745003\n",
      "8\t0.9020219232573582\n",
      "9\t0.8458735386355979\n",
      "10\t0.9279330762285029\n",
      "Total F1-score: 0.9267226234471168\n",
      "Specifities per class: \n",
      "0\t0.9918943955534969\n",
      "1\t0.9998070094179404\n",
      "2\t0.9978385054809326\n",
      "3\t0.9962173845916319\n",
      "4\t0.9988420565076425\n",
      "5\t0.9918557974370851\n",
      "6\t0.9925505635324997\n",
      "7\t0.9942102825382122\n",
      "8\t0.9821676702176934\n",
      "9\t0.9961787864752201\n",
      "10\t0.987037037037037\n",
      "Total specifities: 0.9935090444353992\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "acc = np.sum(accuraciesClass,axis=0)/12\n",
    "print('Accuracy per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(acc[j]))\n",
    "print('Total accuracy: ' + str(sum(acc)/11))\n",
    "'''\n",
    "print('Total accuracy: ' + str(sum(accuracies)/12))\n",
    "\n",
    "prec = np.sum(precision,axis=0)/12\n",
    "print('Precision per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(prec[j]))\n",
    "print('Total precision: ' + str(sum(prec)/11))\n",
    "\n",
    "rec = np.sum(recall,axis=0)/12\n",
    "print('Recall per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(rec[j]))\n",
    "print('Total recall: ' + str(sum(rec)/11))\n",
    "\n",
    "fS = np.sum(fScore,axis=0)/12\n",
    "print('F1-score per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(fS[j]))\n",
    "print('Total F1-score: ' + str(sum(fS)/11))\n",
    "\n",
    "spec = np.sum(specifities,axis=0)/12\n",
    "print('Specifities per class: ')\n",
    "for j in range(11):\n",
    "    print('%d'%(j)+'\\t'+str(spec[j]))\n",
    "print('Total specifities: ' + str(sum(spec)/11))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
