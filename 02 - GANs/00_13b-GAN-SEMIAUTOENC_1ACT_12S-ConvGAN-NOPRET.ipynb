{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERACIÓN DE MOVIMIENTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos necesarios. Asegurarse de poder importarlos.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pylab import rcParams\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\n",
      "3.6.8 (default, Aug 20 2019, 17:12:48) \n",
      "[GCC 8.3.0]\n",
      "sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global activities\n",
    "activities =  [19]\n",
    "global subjects\n",
    "subjects = [1,2,3,5,8,9,10,11,13,14,16,17]\n",
    "subjects_train = [1,3,5,8,9,11,13,14,17]\n",
    "subjects_test = [2,10,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 216\n",
      "Train files: 216\n",
      "TRAINING: \n",
      "['../data_augment/subject_01_AUGMENT_deg_-105_act_19.csv', '../data_augment/subject_01_AUGMENT_deg_-120_act_19.csv', '../data_augment/subject_01_AUGMENT_deg_-135_act_19.csv', '../data_augment/subject_01_AUGMENT_deg_-150_act_19.csv', '../data_augment/subject_01_AUGMENT_deg_-15_act_19.csv', '../data_augment/subject_01_AUGMENT_deg_-165_act_19.csv', '../data_augment/subject_01_AUGMENT_deg_-30_act_19.csv', '../data_augment/subject_01_AUGMENT_deg_-45_act_19.csv', '../data_augment/subject_01_AUGMENT_deg_-60_act_19.csv', '../data_augment/subject_01_AUGMENT_deg_-75_act_19.csv'] ...\n"
     ]
    }
   ],
   "source": [
    "# Ruta raíz\n",
    "PATH = '../data_augment/'\n",
    "\n",
    "quaturls = !ls -1 \"{PATH}\"\n",
    "\n",
    "global activities\n",
    "activities =  [19]\n",
    "subjects = [1,2,3,8,10,13,14,15,16,17]\n",
    "\n",
    "quat_corr = []\n",
    "for filename in quaturls:\n",
    "    for activity in activities:\n",
    "        if(int(filename[-6:-4])==activity):\n",
    "            quat_corr.append(filename)\n",
    "\n",
    "quat_def = []\n",
    "\n",
    "i=0\n",
    "for filename in quat_corr:\n",
    "    for subject in subjects:\n",
    "        if(int(quat_corr[i][8:10])==subject):\n",
    "            quat_def.append(filename)\n",
    "    i+=1\n",
    "\n",
    "quaturls = quat_def\n",
    "\n",
    "del quat_corr, quat_def\n",
    "\n",
    "n = len(quaturls)\n",
    "\n",
    "tr_urls = quaturls\n",
    "\n",
    "print('Total files: ' + str(len(quaturls)))\n",
    "print('Train files: ' + str(len(tr_urls)))\n",
    "\n",
    "tr_fullpath = [os.path.join(PATH,s) for s in tr_urls]\n",
    "print('TRAINING: ')\n",
    "print(str(tr_fullpath[:10]) + ' ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global ind\n",
    "ind=3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(df, n_time_steps, step, segments, labels, label, dim, train, n_channels):\n",
    "    quat0 = df.iloc[:, 1:5][df['QUAT']=='quat0'].reset_index() # si no incluimos el reset_index(), al concatenarlos después\n",
    "    quat1 = df.iloc[:, 1:5][df['QUAT']=='quat1'].reset_index() # aparecerá un dataframe de igual nº de filas que df, pero con\n",
    "    quat2 = df.iloc[:, 1:5][df['QUAT']=='quat2'].reset_index() # NaN en las posiciones que no tienen número de cada dataframe quat,\n",
    "    quat3 = df.iloc[:, 1:5][df['QUAT']=='quat3'].reset_index() # es decir, mantiene los índices de df.\n",
    "    quat4 = df.iloc[:, 1:5][df['QUAT']=='quat4'].reset_index()\n",
    "    \n",
    "    quat = pd.concat([quat0.iloc[:, 1], quat0.iloc[:, 2], quat0.iloc[:, 3], quat0.iloc[:, 4],\n",
    "                      quat1.iloc[:, 1], quat1.iloc[:, 2], quat1.iloc[:, 3], quat1.iloc[:, 4],\n",
    "                      quat2.iloc[:, 1], quat2.iloc[:, 2], quat2.iloc[:, 3], quat2.iloc[:, 4],\n",
    "                      quat3.iloc[:, 1], quat3.iloc[:, 2], quat3.iloc[:, 3], quat3.iloc[:, 4],\n",
    "                      quat4.iloc[:, 1], quat4.iloc[:, 2], quat4.iloc[:, 3], quat4.iloc[:, 4]],\n",
    "                      axis = 1, keys = ['w0', 'x0', 'y0', 'z0', 'w1', 'x1', 'y1', 'z1', 'w2', 'x2', 'y2', 'z2', \n",
    "                                        'w3', 'x3', 'y3', 'z3', 'w4', 'x4', 'y4', 'z4'])\n",
    "    \n",
    "    del quat0, quat1, quat2, quat3, quat4\n",
    "    \n",
    "    if(n_channels == 1):\n",
    "        for i in range(0, quat.shape[0] - n_time_steps, step): # Overlap\n",
    "            # Con listas y numpy\n",
    "            segments.append([])\n",
    "            segments[dim].append(quat.iloc[i: i + n_time_steps, :].values) # Si distinguimos entre sensores\n",
    "            labels.append(label-1)\n",
    "            dim+=1\n",
    "    else:\n",
    "        n_columns = int(36/n_channels)\n",
    "        for i in range(0, quat.shape[0] - n_time_steps, step):\n",
    "            segments.append([])\n",
    "            col = 0\n",
    "            for j in range(n_channels):\n",
    "                segments[dim].append([])\n",
    "                segments[dim][j].append(quat.iloc[i:i+n_time_steps,col:col+n_columns].values)\n",
    "                col+=n_columns\n",
    "            labels.append(label-1)\n",
    "            dim+=1\n",
    "    \n",
    "        \n",
    "    del quat\n",
    "    \n",
    "    return segments, labels, dim\n",
    "\n",
    "\n",
    "def load_quat(path, lim, train, n_channels):\n",
    "\n",
    "    n_time_steps, step = 128, 1  # n_time_steps/50 segundos de actividad y pasos de step/50 segundos (de overlap)\n",
    "    \n",
    "    # Con listas\n",
    "    segments = []\n",
    "    labels = []\n",
    "    \n",
    "    m=1\n",
    "    dim = 0\n",
    "    for filename in path:\n",
    "        print(\"Reading %s (%d/%d)                                                   \"%(filename, m, len(path)), end='\\r')\n",
    "        df = pd.read_csv(filename,sep=',',names=[\"QUAT\",\"w\",\"x\",\"y\",\"z\",\"timestamp\"])\n",
    "        label = int(filename[-6:-4])\n",
    "        for i in range(len(activities)):\n",
    "            if(label==activities[i]):\n",
    "                label=i+1\n",
    "        \n",
    "        segments, labels, dim = sliding_window(df.iloc[:lim], n_time_steps, step, segments, labels, label, dim, train, n_channels)\n",
    "        \n",
    "        m+=1\n",
    "    \n",
    "    del df\n",
    "    \n",
    "    return segments, labels\n",
    "\n",
    "\n",
    "def load_train_quat(filename, lim, n_channels):\n",
    "    return load_quat(filename, lim, True, n_channels)\n",
    "\n",
    "def load_test_quat(filename, lim, n_channels):\n",
    "    return load_quat(filename, lim, False, n_channels)\n",
    "\n",
    "def get_dataset(data_path, lim, batch_size, n_time_steps, train, valid, ds, n_channels):\n",
    "    if(train):\n",
    "        segments, labels = load_train_quat(data_path, lim, n_channels)\n",
    "    else:\n",
    "        segments, labels = load_test_quat(data_path, lim, n_channels)\n",
    "    \n",
    "    print('Generating the dataset                                                   ')                                              \n",
    "    \n",
    "    array = np.asarray(segments, dtype = 'float32')\n",
    "    segments = np.reshape(array, (array.shape[0], n_channels, n_time_steps, int(20/n_channels)))\n",
    "    array = np.asarray(labels, dtype = 'int8')\n",
    "    labels = np.reshape(array, (array.shape[0], 1))\n",
    "    \n",
    "    del array\n",
    "\n",
    "    # Map coninous dataset to categorical (One-Hot)\n",
    "    #labels = keras.utils.to_categorical(labels, 5)\n",
    "    \n",
    "    if(train):\n",
    "        print('-'*20 + 'TRAIN' + '-'*20)\n",
    "    elif(valid):\n",
    "        print('-'*18 + 'VALIDATION' + '-'*12)\n",
    "    else:\n",
    "        print('-'*20 + 'TEST' + '-'*21)\n",
    "    \n",
    "    if(ds):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((segments, labels))\n",
    "    \n",
    "        # It's necessary to repeat our data for all epochs\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        \n",
    "        dataset = dataset.shuffle(segments.shape[0])\n",
    "        \n",
    "        print('Dataset generated                                                        ')\n",
    "        \n",
    "        return dataset, segments, labels\n",
    "    else:\n",
    "        # Shuffle in the first dimension\n",
    "        permutation = np.arange(0,segments.shape[0]-1)\n",
    "        np.random.shuffle(permutation)\n",
    "        segments = segments[permutation]\n",
    "        labels = labels[permutation]\n",
    "        print('Dataset generated                                                        ')\n",
    "        \n",
    "        return segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                                                                     \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "Train dataset: \n",
      "(58751, 1, 128, 20)\n"
     ]
    }
   ],
   "source": [
    "n_time_steps = 128\n",
    "dataset = False # Set to True if you want a dataset or to False if you want np.arrays\n",
    "batch_size = 128 # REAL batch_size\n",
    "n_channels = 1 # It can be 1,4 or 9\n",
    "\n",
    "if(dataset):\n",
    "    train_dataset, tr_seg, tr_lab = get_dataset(tr_fullpath, batch_size, n_time_steps, True, False, dataset, n_channels)\n",
    "    \n",
    "    print('Train dataset: ')\n",
    "    print(train_dataset)\n",
    "else:\n",
    "    tr_seg, _ = get_dataset(tr_fullpath, ind, batch_size, n_time_steps, True, False, dataset, n_channels)\n",
    "    print('Train dataset: ')\n",
    "    print(tr_seg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "input_shape = (1,128,20)\n",
    "batch_size = 128\n",
    "kernel_size = 4\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    return tr_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_optimizer():\n",
    "    return keras.optimizers.Adam(lr=0.00001, beta_1=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gen_input (InputLayer)       [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10240)             1034240   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 64, 32, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 64, 64, 10)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64, 64, 10)        40        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 64, 64, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 128, 20)       32800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 128, 20)       80        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32, 128, 20)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 1, 128, 20)        513       \n",
      "_________________________________________________________________\n",
      "generator_output (Activation (None, 1, 128, 20)        0         \n",
      "=================================================================\n",
      "Total params: 1,133,273\n",
      "Trainable params: 1,133,213\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_generator():\n",
    "    layer_filters = [32,64]\n",
    "    \n",
    "    # Build the Decoder Model\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='gen_input')\n",
    "    x = Dense(64*32*5)(latent_inputs)\n",
    "    x = Reshape((64, 32, 5))(x)\n",
    "\n",
    "    # Stack of Transposed Conv2D blocks\n",
    "    # Notes:\n",
    "    # 1) Use Batch Normalization before ReLU on deep networks\n",
    "    # 2) Use UpSampling2D as alternative to strides>1\n",
    "    # - faster but not as good as strides>1\n",
    "    for filters in layer_filters[::-1]:\n",
    "        x = Conv2DTranspose(filters=filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            strides=2,\n",
    "                            padding='same',\n",
    "                            data_format = 'channels_first',\n",
    "                            kernel_initializer = RandomNormal(mean=0.0, stddev=0.02))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters=1,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same',\n",
    "                        data_format='channels_first',\n",
    "                        kernel_initializer = RandomNormal(mean=0.0, stddev=0.02))(x)\n",
    "\n",
    "    outputs = Activation('tanh', name='generator_output')(x)\n",
    "\n",
    "    # Instantiate Decoder Model\n",
    "    generator = Model(latent_inputs, outputs, name='generator')\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.00001, beta_1=0.5, clipnorm=0.1))\n",
    "    \n",
    "    return generator\n",
    "\n",
    "generator=create_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa [(None, 1, 128, 20)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 64, 10)        544       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 64, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 32, 5)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 32, 5)         20        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 32, 5)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 32, 5)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "activity_class (Dense)       (None, 1)                 10241     \n",
      "=================================================================\n",
      "Total params: 43,637\n",
      "Trainable params: 43,627\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_discriminator():  \n",
    "    layer_filters = [32,64]\n",
    "    \n",
    "    inputs = Input(shape=(1,128,20), name='discriminator_input')\n",
    "    x = inputs\n",
    "\n",
    "    i=0\n",
    "    for filters in layer_filters:\n",
    "        x = Conv2D(filters=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=2,\n",
    "                    padding='same',\n",
    "                    data_format='channels_first',\n",
    "                    kernel_initializer = RandomNormal(mean=0.0, stddev=0.02))(x)\n",
    "        if(i!=0):\n",
    "            x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        i+=1\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    output = Dense(1, name='activity_class', activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "    # Instantiate Encoder Model\n",
    "    discriminator = Model(inputs, output, name='discriminator')\n",
    "    discriminator.compile(optimizer=keras.optimizers.Adam(lr=0.00001, beta_1=0.5, clipnorm=0.1), loss='binary_crossentropy')\n",
    "    return discriminator\n",
    "discriminator =create_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "generator (Model)            (None, 1, 128, 20)        1133273   \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        (None, 1)                 43637     \n",
      "=================================================================\n",
      "Total params: 1,176,910\n",
      "Trainable params: 1,133,213\n",
      "Non-trainable params: 43,697\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    discriminator.trainable=False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output= discriminator(x)\n",
    "    gan= Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.00001, beta_1=0.5, clipnorm=0.1))\n",
    "    return gan\n",
    "gan = create_gan(discriminator,generator)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(name, ts_seg):\n",
    "    fo = open(name, \"w\")\n",
    "    head = \"QUAT,w,x,y,z,timestamp\\n\"\n",
    "    fo.seek(0,2)\n",
    "    fo.write(head)\n",
    "    fo.close()\n",
    "    \n",
    "    fo = open(name, \"a\")\n",
    "    salida = np.reshape(ts_seg, (ts_seg.shape[0]*ts_seg.shape[2], ts_seg.shape[3]))\n",
    "    \n",
    "    k = 0\n",
    "    for i in range(salida.shape[0]):\n",
    "        if(i%128==0):\n",
    "            if(i!=0):\n",
    "                k+=1\n",
    "        print('%d'%(i), end='\\r')\n",
    "        fo.write(\"quat0,\"+str(salida[i][0])+\",\"+str(salida[i][1])+\",\"+str(salida[i][2])+\",\"+str(salida[i][3])+\",\"+str(i)+\",\"+'\\n')\n",
    "        fo.write(\"quat1,\"+str(salida[i][4])+\",\"+str(salida[i][5])+\",\"+str(salida[i][6])+\",\"+str(salida[i][7])+\",\"+str(i)+\",\"+'\\n')\n",
    "        fo.write(\"quat2,\"+str(salida[i][8])+\",\"+str(salida[i][9])+\",\"+str(salida[i][10])+\",\"+str(salida[i][11])+\",\"+str(i)+\",\"+'\\n')\n",
    "        fo.write(\"quat3,\"+str(salida[i][12])+\",\"+str(salida[i][13])+\",\"+str(salida[i][14])+\",\"+str(salida[i][15])+\",\"+str(i)+\",\"+'\\n')\n",
    "        fo.write(\"quat4,\"+str(salida[i][16])+\",\"+str(salida[i][17])+\",\"+str(salida[i][18])+\",\"+str(salida[i][19])+\",\"+str(i)+\",\"+'\\n')\n",
    "        if(salida.shape[1]==36):\n",
    "            fo.write(\"quat5,\"+str(salida[i][20])+\",\"+str(salida[i][21])+\",\"+str(salida[i][22])+\",\"+str(salida[i][23])+\",\"+str(i)+\",\"+'\\n')\n",
    "            fo.write(\"quat6,\"+str(salida[i][24])+\",\"+str(salida[i][25])+\",\"+str(salida[i][26])+\",\"+str(salida[i][27])+\",\"+str(i)+\",\"+'\\n')\n",
    "            fo.write(\"quat7,\"+str(salida[i][28])+\",\"+str(salida[i][29])+\",\"+str(salida[i][30])+\",\"+str(salida[i][31])+\",\"+str(i)+\",\"+'\\n')\n",
    "            fo.write(\"quat8,\"+str(salida[i][32])+\",\"+str(salida[i][33])+\",\"+str(salida[i][34])+\",\"+str(salida[i][35])+\",\"+str(i)+\",\"+'\\n')\n",
    "        else:\n",
    "            fo.write(\"quat5,\"+str(1)+\",\"+str(0)+\",\"+str(0)+\",\"+str(0)+\",\"+str(i)+\",\"+'\\n')\n",
    "            fo.write(\"quat6,\"+str(1)+\",\"+str(0)+\",\"+str(0)+\",\"+str(0)+\",\"+str(i)+\",\"+'\\n')\n",
    "            fo.write(\"quat7,\"+str(1)+\",\"+str(0)+\",\"+str(0)+\",\"+str(0)+\",\"+str(i)+\",\"+'\\n')\n",
    "            fo.write(\"quat8,\"+str(1)+\",\"+str(0)+\",\"+str(0)+\",\"+str(0)+\",\"+str(i)+\",\"+'\\n')\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rutina de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 4\n",
      "25: [D loss REAL : 0.003135]  [D loss FAKE: 4.411164]  [A loss: 0.019301]\r"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def training(epochs=1, batch_size=128):\n",
    "    \n",
    "    #Loading the data\n",
    "    tr_seg = load_data()\n",
    "    batch_count = tr_seg.shape[0] // batch_size\n",
    "    X_train = tr_seg\n",
    "    \n",
    "    # Creating GAN\n",
    "    generator= create_generator()\n",
    "    discriminator= create_discriminator()\n",
    "    gan = create_gan(discriminator, generator)\n",
    "    \n",
    "    d_real_hist = []\n",
    "    d_fake_hist = []\n",
    "    a_hist = []\n",
    "\n",
    "    for e in range(1,epochs+1 ):\n",
    "        print(\"\\n Epoch %d\" %e)\n",
    "        for i in range (batch_count):\n",
    "        #generate  random noise as an input  to  initialize the  generator\n",
    "            noise= np.random.normal(0,1, [batch_size, 100])\n",
    "            \n",
    "            #Pre train discriminator on  fake and real data  before starting the gan. \n",
    "            discriminator.trainable=True\n",
    "            \n",
    "            # Get a random set of  real images\n",
    "            image_batch =X_train[np.random.randint(low=0,high=X_train.shape[0],size=batch_size)]\n",
    "            y_dis=np.ones(batch_size)\n",
    "            \n",
    "            d_loss_real=discriminator.train_on_batch(image_batch, y_dis)\n",
    "            \n",
    "            # Generate fake MNIST images from noised input\n",
    "            generated_images = generator.predict(noise)\n",
    "            y_dis=np.zeros(batch_size)\n",
    "            \n",
    "            d_loss_fake=discriminator.train_on_batch(generated_images, y_dis)\n",
    "            \n",
    "            #Tricking the noised input of the Generator as real data\n",
    "            noise= np.random.normal(0,1, [batch_size, 100])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            \n",
    "            # During the training of gan, \n",
    "            # the weights of discriminator should be fixed. \n",
    "            #We can enforce that by setting the trainable flag\n",
    "            discriminator.trainable=False\n",
    "            \n",
    "            #training  the GAN by alternating the training of the Discriminator \n",
    "            #and training the chained GAN model with Discriminator’s weights freezed.\n",
    "            # keras.utils.to_categorical(y_gen, 2)\n",
    "            a_loss=gan.train_on_batch(noise,  y_gen)\n",
    "            \n",
    "            d_real_hist.append(d_loss_real)\n",
    "            d_fake_hist.append(d_loss_fake)\n",
    "            a_hist.append(a_loss)\n",
    "            \n",
    "            log_mesg = \"%d: [D loss REAL : %f]\" % (i+1, d_loss_real)\n",
    "            log_mesg = \"%s  [D loss FAKE: %f]\" % (log_mesg, d_loss_fake)\n",
    "            log_mesg = \"%s  [A loss: %f]\" % (log_mesg, a_loss)\n",
    "            print(log_mesg, end='\\r')\n",
    "            \n",
    "        if e == 1 or e % 100 == 0:\n",
    "            name = \"./00_13b_models/generated_00_13b_%s.csv\"%(e)\n",
    "            write(name, generated_images)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "    return generator, discriminator, gan, d_real_hist, d_fake_hist, a_hist\n",
    "\n",
    "epochs = 600 # 600\n",
    "batch_size = 128 # 128\n",
    "generator, discriminator, gan, d_real_hist, d_fake_hist, a_hist = training(epochs,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "generator.save('./00_13b_models/generator.h5')\n",
    "print('Generator saved.')\n",
    "discriminator.save('./00_13b_models/discriminator.h5')\n",
    "print('Discriminator saved.')\n",
    "gan.save('./00_13b_models/GAN.h5')\n",
    "print('GAN saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"./00_13b_models/12.txt\", \"w\")\n",
    "fo.write(\"Op. terminada\")\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = tr_seg.shape[0] // batch_size\n",
    "\n",
    "x_ticks = np.linspace(1,epochs,num=len(d_real_hist))\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(x_ticks,d_real_hist, label='Disc. loss REAL')\n",
    "plt.plot(x_ticks,d_fake_hist, label='Disc. loss FAKE')\n",
    "plt.plot(x_ticks,a_hist, label='Adv. loss')\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Losses', fontsize=20)\n",
    "plt.legend(loc=1, prop={'size': 20})\n",
    "plt.tick_params(labelsize=20);\n",
    "plt.title('GAN Training', fontsize=20)\n",
    "\n",
    "plt.draw()\n",
    "plt.savefig('./00_13b_models/training.tiff', bbox_inches='tight',format='tiff')\n",
    "plt.draw()\n",
    "plt.savefig('./00_13b_models/training.pdf', bbox_inches='tight',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(x_ticks,d_real_hist, label='Disc. loss REAL')\n",
    "plt.plot(x_ticks,d_fake_hist, label='Disc. loss FAKE')\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Losses', fontsize=20)\n",
    "plt.legend(loc=1, prop={'size': 20})\n",
    "plt.tick_params(labelsize=20);\n",
    "plt.title('GAN Training', fontsize=20)\n",
    "\n",
    "plt.draw()\n",
    "plt.savefig('./00_13b_models/training_noAdv.tiff', bbox_inches='tight',format='tiff')\n",
    "plt.draw()\n",
    "plt.savefig('./00_13b_models/training_noAdv.pdf', bbox_inches='tight',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_hist = np.asarray(d_real_hist)+np.asarray(d_fake_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(x_ticks,d_hist, label='Disc. loss')\n",
    "plt.plot(x_ticks,a_hist, label='Adv. loss')\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Losses', fontsize=20)\n",
    "plt.legend(loc=1, prop={'size': 20})\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.title('GAN Training', fontsize=20)\n",
    "\n",
    "plt.draw()\n",
    "plt.savefig('./00_13b_models/training2.tiff', bbox_inches='tight',format='tiff')\n",
    "plt.draw()\n",
    "plt.savefig('./00_13b_models/training2.pdf', bbox_inches='tight',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(x_ticks,d_hist, label='Disc. loss')\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Losses', fontsize=20)\n",
    "plt.legend(loc=1, prop={'size': 20})\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.title('GAN Training', fontsize=20)\n",
    "\n",
    "plt.draw()\n",
    "plt.savefig('./00_13b_models/training2_noAdv.tiff', bbox_inches='tight',format='tiff')\n",
    "plt.draw()\n",
    "plt.savefig('./00_13b_models/training2_noAdv.pdf', bbox_inches='tight',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_real_hist[-1])\n",
    "print(d_fake_hist[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
