{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos necesarios. Asegurarse de poder importarlos.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pylab import rcParams\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import os as os\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\n",
      "3.6.8 (default, Aug 20 2019, 17:12:48) \n",
      "[GCC 8.3.0]\n",
      "sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos uso de los ficheros que contiene los cuaterniones separados por sujetos y actividad.\n",
    "\n",
    "Definimos una serie de funciones para la lectura de los datos y finalmente realizamos el dataset (así leemos los datos en el entrenamiento \"al vuelo\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta raíz\n",
    "PATH = '../data_reset_def_raworientation_ALL_SENSORS'\n",
    "\n",
    "# Ruta de los ceckpoints\n",
    "CKPATH = PATH + '/checkpoints'\n",
    "\n",
    "quaturls = !ls -1 \"{PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_act = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global activities\n",
    "activities = [9,10,11,12,13,19,20,21,24,25,31]\n",
    "activities = activities[:n_act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "quat_corr = []\n",
    "for filename in quaturls:\n",
    "    for activity in activities:\n",
    "        if(int(filename[-6:-4])==activity):\n",
    "            quat_corr.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "global subjects\n",
    "subjects = [1,2,3,5,8,9,10,11,13,14,16,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quaturls = []\n",
    "\n",
    "i=0\n",
    "for filename in quat_corr:\n",
    "    for subject in subjects:\n",
    "        if(int(quat_corr[i][8:10])==subject):\n",
    "            quaturls.append(filename)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación por sujetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 132\n"
     ]
    }
   ],
   "source": [
    "print('Total files: ' + str(len(quaturls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: \n",
      "['../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_10.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_11.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_12.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_13.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_19.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_20.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_21.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_24.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_25.csv']\n"
     ]
    }
   ],
   "source": [
    "data_fullpath = [os.path.join(PATH,s) for s in quaturls]\n",
    "print('DATA: ')\n",
    "print(data_fullpath[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceo entre clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el balanceo de clases forzamos a que cada clase tenga el mismo número de muestras, así que, en este caso, limitamos el nº de muestras al que tiene el mínimo (en el futuro sehará data augmentation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_reset_def_raworientation_ALL_SENSORS/subject_16_RESET_RAW_act_24.csv\r"
     ]
    }
   ],
   "source": [
    "n = 1e1000\n",
    "for filename in data_fullpath:\n",
    "    df = pd.read_csv(filename,sep=',') \n",
    "    \n",
    "    ind = len(df.index)\n",
    "    if(ind!=0 and ind<n):\n",
    "        n = ind\n",
    "        print(filename, end='\\r')\n",
    "\n",
    "ind_tr = int(n)\n",
    "if(PATH == '../data_augment'):\n",
    "    ind_real = 24*int(n/9)\n",
    "else:\n",
    "    ind_real = int(n/9)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos: 401 muestras de cada actividad de cada sujeto, que se corresponde con: 8.02 segundos.\n"
     ]
    }
   ],
   "source": [
    "print('Tenemos: '+ str(ind_real) + ' muestras de cada actividad de cada sujeto, que se corresponde con: '+ str(ind_real/50) + ' segundos.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3609\n"
     ]
    }
   ],
   "source": [
    "print(ind_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación por sujetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2, s3, s5, s8, s9, s10, s11, s13, s14, s16, s17 = [], [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "i=0\n",
    "for filename in data_fullpath:\n",
    "    if(int(data_fullpath[i][53:55])==1):\n",
    "        s1.append(filename)\n",
    "    elif(int(data_fullpath[i][53:55])==2):\n",
    "        s2.append(filename)\n",
    "    elif(int(data_fullpath[i][53:55])==3):\n",
    "        s3.append(filename)\n",
    "    elif(int(data_fullpath[i][53:55])==5):\n",
    "        s5.append(filename)\n",
    "    elif(int(data_fullpath[i][53:55])==8):\n",
    "        s8.append(filename)\n",
    "    elif(int(data_fullpath[i][53:55])==9):\n",
    "        s9.append(filename)\n",
    "    elif(int(data_fullpath[i][53:55])==10):\n",
    "        s10.append(filename)\n",
    "    elif(int(data_fullpath[i][53:55])==11):\n",
    "        s11.append(filename)\n",
    "    elif(int(data_fullpath[i][53:55])==13):\n",
    "        s13.append(filename)\n",
    "    elif(int(data_fullpath[i][53:55])==14):\n",
    "        s14.append(filename)\n",
    "    elif(int(data_fullpath[i][53:55])==16):\n",
    "        s16.append(filename)\n",
    "    elif(int(data_fullpath[i][53:55])==17):\n",
    "        s17.append(filename)\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_02_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_02_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_03_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_03_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_05_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_05_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_08_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_08_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_09_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_09_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_10_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_10_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_11_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_11_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_13_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_13_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_14_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_14_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_16_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_16_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_17_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_17_RESET_RAW_act_10.csv']\n"
     ]
    }
   ],
   "source": [
    "print(s1[:2], s2[:2], s3[:2], s5[:2], s8[:2], s9[:2], s10[:2], s11[:2], s13[:2], s14[:2], s16[:2], s17[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con listas y numpy (la más pesada de todas, pero seguros en que mantiene la estructura de los datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(df, n_time_steps, step, segments, labels, label, dim, train, n_channels):\n",
    "    quat0 = df.iloc[:, 1:5][df['QUAT']=='quat0'].reset_index() # si no incluimos el reset_index(), al concatenarlos después\n",
    "    quat1 = df.iloc[:, 1:5][df['QUAT']=='quat1'].reset_index() # aparecerá un dataframe de igual nº de filas que df, pero con\n",
    "    quat2 = df.iloc[:, 1:5][df['QUAT']=='quat2'].reset_index() # NaN en las posiciones que no tienen número de cada dataframe quat,\n",
    "    quat3 = df.iloc[:, 1:5][df['QUAT']=='quat3'].reset_index() # es decir, mantiene los índices de df.\n",
    "    quat4 = df.iloc[:, 1:5][df['QUAT']=='quat4'].reset_index()\n",
    "    quat5 = df.iloc[:, 1:5][df['QUAT']=='quat5'].reset_index()\n",
    "    quat6 = df.iloc[:, 1:5][df['QUAT']=='quat6'].reset_index()\n",
    "    quat7 = df.iloc[:, 1:5][df['QUAT']=='quat7'].reset_index()\n",
    "    quat8 = df.iloc[:, 1:5][df['QUAT']=='quat8'].reset_index()\n",
    "    \n",
    "    quat = pd.concat([quat0.iloc[:, 1], quat0.iloc[:, 2], quat0.iloc[:, 3], quat0.iloc[:, 4],\n",
    "                      quat1.iloc[:, 1], quat1.iloc[:, 2], quat1.iloc[:, 3], quat1.iloc[:, 4],\n",
    "                      quat2.iloc[:, 1], quat2.iloc[:, 2], quat2.iloc[:, 3], quat2.iloc[:, 4],\n",
    "                      quat3.iloc[:, 1], quat3.iloc[:, 2], quat3.iloc[:, 3], quat3.iloc[:, 4],\n",
    "                      quat4.iloc[:, 1], quat4.iloc[:, 2], quat4.iloc[:, 3], quat4.iloc[:, 4],\n",
    "                      quat5.iloc[:, 1], quat5.iloc[:, 2], quat5.iloc[:, 3], quat5.iloc[:, 4],\n",
    "                      quat6.iloc[:, 1], quat6.iloc[:, 2], quat6.iloc[:, 3], quat6.iloc[:, 4],\n",
    "                      quat7.iloc[:, 1], quat7.iloc[:, 2], quat7.iloc[:, 3], quat7.iloc[:, 4],\n",
    "                      quat8.iloc[:, 1], quat8.iloc[:, 2], quat8.iloc[:, 3], quat8.iloc[:, 4]],\n",
    "                      axis = 1, keys = ['w0', 'x0', 'y0', 'z0', 'w1', 'x1', 'y1', 'z1', 'w2', 'x2', 'y2', 'z2', \n",
    "                                        'w3', 'x3', 'y3', 'z3', 'w4', 'x4', 'y4', 'z4', 'w5', 'x5', 'y5', 'z5',\n",
    "                                        'w6', 'x6', 'y6', 'z6', 'w7', 'x7', 'y7', 'z7', 'w8', 'x8', 'y8', 'z8'])\n",
    "    del quat0, quat1, quat2, quat3, quat4, quat5, quat6, quat7, quat8\n",
    "    \n",
    "    if(train==False):\n",
    "        step = n_time_steps//2\n",
    "    \n",
    "    if(n_channels == 1):\n",
    "        for i in range(0, quat.shape[0] - n_time_steps, step): # Overlap\n",
    "            # Con listas y numpy\n",
    "            segments.append([])\n",
    "            segments[dim].append(quat.iloc[i: i + n_time_steps, :].values) # Si distinguimos entre sensores\n",
    "            labels.append(int(label-1))\n",
    "            dim+=1\n",
    "    else:\n",
    "        n_columns = int(36/n_channels)\n",
    "        for i in range(0, quat.shape[0] - n_time_steps, step):\n",
    "            segments.append([])\n",
    "            col = 0\n",
    "            for j in range(n_channels):\n",
    "                segments[dim].append([])\n",
    "                segments[dim][j].append(quat.iloc[i:i+n_time_steps,col:col+n_columns].values)\n",
    "                col+=n_columns\n",
    "            labels.append(label-1)\n",
    "            dim+=1\n",
    "    \n",
    "        \n",
    "    del quat\n",
    "    \n",
    "    return segments, labels, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_quat(path, lim, train, n_channels):\n",
    "\n",
    "    step = n_time_steps//4  # n_time_steps/50 segundos de actividad y pasos de step/50 segundos (de overlap)\n",
    "    \n",
    "    # Con listas\n",
    "    segments = []\n",
    "    labels = []\n",
    "    \n",
    "    i=1\n",
    "    dim = 0\n",
    "    for filename in path:\n",
    "        print(\"Reading %s (%d/%d)                                                   \"%(filename, i, len(path)), end='\\r')\n",
    "        df = pd.read_csv(filename,sep=',',names=[\"QUAT\",\"w\",\"x\",\"y\",\"z\",\"timestamp\"])\n",
    "        label = int(filename[-6:-4])\n",
    "        for k in range(len(activities)):\n",
    "            if(label==activities[k]):\n",
    "                label=k+1\n",
    "        \n",
    "        segments, labels, dim = sliding_window(df.iloc[:lim], n_time_steps, step, segments, labels, label, dim, train, n_channels)\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    del df\n",
    "    \n",
    "    return segments, labels\n",
    "\n",
    "\n",
    "def load_train_quat(filename, lim, n_channels):\n",
    "    return load_quat(filename, lim, True, n_channels)\n",
    "\n",
    "def load_test_quat(filename, lim, n_channels):\n",
    "    return load_quat(filename, lim, False, n_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data_path, lim, batch_size, n_time_steps, train, valid, ds, n_channels):\n",
    "    if(train):\n",
    "        segments, labels = load_train_quat(data_path, lim, n_channels)\n",
    "    else:\n",
    "        segments, labels = load_test_quat(data_path, lim, n_channels)\n",
    "    \n",
    "    print('Generating the dataset                                                   ')                                              \n",
    "    \n",
    "    array = np.asarray(segments, dtype = 'float32')\n",
    "    segments = np.reshape(array, (array.shape[0], n_channels, n_time_steps, int(36/n_channels)))\n",
    "    array = np.asarray(labels, dtype = 'int8')\n",
    "    labels = np.reshape(array, (array.shape[0], 1))\n",
    "    \n",
    "    del array\n",
    "\n",
    "    # Map coninous dataset to categorical (One-Hot)\n",
    "    labels = keras.utils.to_categorical(labels, len(activities))\n",
    "    \n",
    "    if(train):\n",
    "        print('-'*20 + 'TRAIN' + '-'*20)\n",
    "    elif(valid):\n",
    "        print('-'*18 + 'VALIDATION' + '-'*17)\n",
    "    else:\n",
    "        print('-'*20 + 'TEST' + '-'*21)\n",
    "    \n",
    "    if(ds):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((segments, labels))\n",
    "    \n",
    "        # It's necessary to repeat our data for all epochs\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        \n",
    "        dataset = dataset.shuffle(segments.shape[0])\n",
    "        \n",
    "        print('Dataset generated                                                        ')\n",
    "        \n",
    "        return dataset, segments, labels\n",
    "    else:\n",
    "        np.random.seed(235)\n",
    "        # Shuffle in the first dimension\n",
    "        permutation = np.arange(0,segments.shape[0]-1)\n",
    "        np.random.shuffle(permutation)\n",
    "        segments = segments[permutation]\n",
    "        labels = labels[permutation]\n",
    "        print('Dataset generated                                                        ')\n",
    "        \n",
    "        return segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "global n_time_steps\n",
    "n_time_steps = 128\n",
    "\n",
    "def generator(s):\n",
    "    dataset = False # Set to True if you want a dataset or to False if you want np.arrays\n",
    "    batch_size = 32 # REAL batch_size\n",
    "    n_channels = 1 # It can be 1,4 or 9\n",
    "\n",
    "    subj = s[0][53:55]\n",
    "\n",
    "    seg, lab = get_dataset(s, ind_tr, batch_size, n_time_steps, True, False, dataset, n_channels)\n",
    "    \n",
    "    print(seg.shape, lab.shape)\n",
    "\n",
    "    np.save('./def_raworientation_ALL_SENSORS/subject_video_'+subj+'_seg.npy', seg)\n",
    "    np.save('./def_raworientation_ALL_SENSORS/subject_video_'+subj+'_lab.npy', lab)\n",
    "    \n",
    "    print('Files from subject ' + subj + ' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 01 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 02 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 03 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 05 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 08 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 09 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 10 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 11 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 13 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 14 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 16 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
      "--------------------TRAIN--------------------\n",
      "Dataset generated                                                        \n",
      "(98, 1, 128, 36) (98, 11)\n",
      "Files from subject 17 saved\n"
     ]
    }
   ],
   "source": [
    "generator(s17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operación terminada.\n"
     ]
    }
   ],
   "source": [
    "print('Operación terminada.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
