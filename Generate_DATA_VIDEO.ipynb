{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnGyk2eJWtIQ"
      },
      "source": [
        "# Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL6EoBhqWtIR"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE92C5s8WtIS"
      },
      "outputs": [],
      "source": [
        "# Módulos necesarios. Asegurarse de poder importarlos.\n",
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "from six.moves import cPickle as pickle\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import csv\n",
        "from pylab import rcParams\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "import os as os\n",
        "from mpl_toolkits.axes_grid1 import host_subplot\n",
        "import mpl_toolkits.axisartist as AA\n",
        "\n",
        "# Config the matplotlib backend as plotting inline in IPython\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGpEwc_tWtIS",
        "outputId": "dfe5ed30-195b-4dd6-caa5-52ee5722bd45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/bin/python\n",
            "3.6.8 (default, Aug 20 2019, 17:12:48) \n",
            "[GCC 8.3.0]\n",
            "sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)\n",
        "print(sys.version)\n",
        "print(sys.version_info)\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDEN7eB2WtIT",
        "outputId": "5b012a7e-2c84-4ff9-a35a-9d8c9cd8a455"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.2.4-tf'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keras.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQvKtTKTWzum"
      },
      "source": [
        "# Dataset generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHJA2Ic4Wzun"
      },
      "source": [
        "I make use of the files that contain the quaternions differnatiated per subject and activity.\n",
        "\n",
        "I define a number of functions to read the data and finally generated the dataset 'on the fly'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbo8v3AhWtIT"
      },
      "outputs": [],
      "source": [
        "# Root path\n",
        "PATH = '../data_reset_def_raworientation_ALL_SENSORS'\n",
        "\n",
        "#Checkpoints path\n",
        "CKPATH = PATH + '/checkpoints'\n",
        "\n",
        "quaturls = !ls -1 \"{PATH}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC9zJ-CcWtIT"
      },
      "outputs": [],
      "source": [
        "n_act = 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDCgXcimWtIU"
      },
      "outputs": [],
      "source": [
        "global activities\n",
        "activities = [9,10,11,12,13,19,20,21,24,25,31]\n",
        "activities = activities[:n_act]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz3MkAL3WtIU"
      },
      "outputs": [],
      "source": [
        "quat_corr = []\n",
        "for filename in quaturls:\n",
        "    for activity in activities:\n",
        "        if(int(filename[-6:-4])==activity):\n",
        "            quat_corr.append(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjugOOi7WtIU"
      },
      "outputs": [],
      "source": [
        "global subjects\n",
        "subjects = [1,2,3,5,8,9,10,11,13,14,16,17]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMkiLkGbWtIU"
      },
      "outputs": [],
      "source": [
        "quaturls = []\n",
        "\n",
        "i=0\n",
        "for filename in quat_corr:\n",
        "    for subject in subjects:\n",
        "        if(int(quat_corr[i][8:10])==subject):\n",
        "            quaturls.append(filename)\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d17gaBO9Wzun"
      },
      "source": [
        "### Differentiating per subject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wm8f4tzWtIU",
        "outputId": "33583bae-4f57-40ae-bf0c-88ce66c49469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total files: 132\n"
          ]
        }
      ],
      "source": [
        "print('Total files: ' + str(len(quaturls)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euIOJm7JWtIU",
        "outputId": "48d797d2-dac5-4e19-eb08-903a284af57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA: \n",
            "['../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_10.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_11.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_12.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_13.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_19.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_20.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_21.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_24.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_25.csv']\n"
          ]
        }
      ],
      "source": [
        "data_fullpath = [os.path.join(PATH,s) for s in quaturls]\n",
        "print('DATA: ')\n",
        "print(data_fullpath[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ew7v3VkWzuo"
      },
      "source": [
        "### Class balancing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXqzrV_CWzuo"
      },
      "source": [
        "For class balancing we make each class have the same number of samples, so we limit it to the minimum-class number (there will be data augmentation afterwards):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKN9DeUWWtIU",
        "outputId": "f90ce4c7-d074-44e7-a42a-b0a230a2900c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "../data_reset_def_raworientation_ALL_SENSORS/subject_16_RESET_RAW_act_24.csv\r"
          ]
        }
      ],
      "source": [
        "n = 1e1000\n",
        "for filename in data_fullpath:\n",
        "    df = pd.read_csv(filename,sep=',')\n",
        "\n",
        "    ind = len(df.index)\n",
        "    if(ind!=0 and ind<n):\n",
        "        n = ind\n",
        "        print(filename, end='\\r')\n",
        "\n",
        "ind_tr = int(n)\n",
        "if(PATH == '../data_augment'):\n",
        "    ind_real = 24*int(n/9)\n",
        "else:\n",
        "    ind_real = int(n/9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnFp2MGdWtIV",
        "outputId": "115f6344-814b-4ea4-decb-50c1f5b07a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tenemos: 401 muestras de cada actividad de cada sujeto, que se corresponde con: 8.02 segundos.\n"
          ]
        }
      ],
      "source": [
        "print('Tenemos: '+ str(ind_real) + ' muestras de cada actividad de cada sujeto, que se corresponde con: '+ str(ind_real/50) + ' segundos.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phBq_DS4WtIV",
        "outputId": "e5332b20-289e-4513-e47f-d63af01ce3c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3609\n"
          ]
        }
      ],
      "source": [
        "print(ind_tr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMrScuzHWzuo"
      },
      "source": [
        "### Differentiating per subject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir80c36UWtIV"
      },
      "outputs": [],
      "source": [
        "s1, s2, s3, s5, s8, s9, s10, s11, s13, s14, s16, s17 = [], [], [], [], [], [], [], [], [], [], [], []\n",
        "\n",
        "i=0\n",
        "for filename in data_fullpath:\n",
        "    if(int(data_fullpath[i][53:55])==1):\n",
        "        s1.append(filename)\n",
        "    elif(int(data_fullpath[i][53:55])==2):\n",
        "        s2.append(filename)\n",
        "    elif(int(data_fullpath[i][53:55])==3):\n",
        "        s3.append(filename)\n",
        "    elif(int(data_fullpath[i][53:55])==5):\n",
        "        s5.append(filename)\n",
        "    elif(int(data_fullpath[i][53:55])==8):\n",
        "        s8.append(filename)\n",
        "    elif(int(data_fullpath[i][53:55])==9):\n",
        "        s9.append(filename)\n",
        "    elif(int(data_fullpath[i][53:55])==10):\n",
        "        s10.append(filename)\n",
        "    elif(int(data_fullpath[i][53:55])==11):\n",
        "        s11.append(filename)\n",
        "    elif(int(data_fullpath[i][53:55])==13):\n",
        "        s13.append(filename)\n",
        "    elif(int(data_fullpath[i][53:55])==14):\n",
        "        s14.append(filename)\n",
        "    elif(int(data_fullpath[i][53:55])==16):\n",
        "        s16.append(filename)\n",
        "    elif(int(data_fullpath[i][53:55])==17):\n",
        "        s17.append(filename)\n",
        "\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqVfQ6AxWtIV",
        "outputId": "9cad7462-b2f0-4592-9735-167b661b5102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_01_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_02_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_02_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_03_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_03_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_05_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_05_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_08_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_08_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_09_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_09_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_10_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_10_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_11_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_11_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_13_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_13_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_14_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_14_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_16_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_16_RESET_RAW_act_10.csv'] ['../data_reset_def_raworientation_ALL_SENSORS/subject_17_RESET_RAW_act_09.csv', '../data_reset_def_raworientation_ALL_SENSORS/subject_17_RESET_RAW_act_10.csv']\n"
          ]
        }
      ],
      "source": [
        "print(s1[:2], s2[:2], s3[:2], s5[:2], s8[:2], s9[:2], s10[:2], s11[:2], s13[:2], s14[:2], s16[:2], s17[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJkzNNl1Wzuo"
      },
      "source": [
        "### Working with lists and numpy (heavier but helps to keep dimensions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeeSDNT7WtIV"
      },
      "outputs": [],
      "source": [
        "def sliding_window(df, n_time_steps, step, segments, labels, label, dim, train, n_channels):\n",
        "    quat0 = df.iloc[:, 1:5][df['QUAT']=='quat0'].reset_index() # si no incluimos el reset_index(), al concatenarlos después\n",
        "    quat1 = df.iloc[:, 1:5][df['QUAT']=='quat1'].reset_index() # aparecerá un dataframe de igual nº de filas que df, pero con\n",
        "    quat2 = df.iloc[:, 1:5][df['QUAT']=='quat2'].reset_index() # NaN en las posiciones que no tienen número de cada dataframe quat,\n",
        "    quat3 = df.iloc[:, 1:5][df['QUAT']=='quat3'].reset_index() # es decir, mantiene los índices de df.\n",
        "    quat4 = df.iloc[:, 1:5][df['QUAT']=='quat4'].reset_index()\n",
        "    quat5 = df.iloc[:, 1:5][df['QUAT']=='quat5'].reset_index()\n",
        "    quat6 = df.iloc[:, 1:5][df['QUAT']=='quat6'].reset_index()\n",
        "    quat7 = df.iloc[:, 1:5][df['QUAT']=='quat7'].reset_index()\n",
        "    quat8 = df.iloc[:, 1:5][df['QUAT']=='quat8'].reset_index()\n",
        "\n",
        "    quat = pd.concat([quat0.iloc[:, 1], quat0.iloc[:, 2], quat0.iloc[:, 3], quat0.iloc[:, 4],\n",
        "                      quat1.iloc[:, 1], quat1.iloc[:, 2], quat1.iloc[:, 3], quat1.iloc[:, 4],\n",
        "                      quat2.iloc[:, 1], quat2.iloc[:, 2], quat2.iloc[:, 3], quat2.iloc[:, 4],\n",
        "                      quat3.iloc[:, 1], quat3.iloc[:, 2], quat3.iloc[:, 3], quat3.iloc[:, 4],\n",
        "                      quat4.iloc[:, 1], quat4.iloc[:, 2], quat4.iloc[:, 3], quat4.iloc[:, 4],\n",
        "                      quat5.iloc[:, 1], quat5.iloc[:, 2], quat5.iloc[:, 3], quat5.iloc[:, 4],\n",
        "                      quat6.iloc[:, 1], quat6.iloc[:, 2], quat6.iloc[:, 3], quat6.iloc[:, 4],\n",
        "                      quat7.iloc[:, 1], quat7.iloc[:, 2], quat7.iloc[:, 3], quat7.iloc[:, 4],\n",
        "                      quat8.iloc[:, 1], quat8.iloc[:, 2], quat8.iloc[:, 3], quat8.iloc[:, 4]],\n",
        "                      axis = 1, keys = ['w0', 'x0', 'y0', 'z0', 'w1', 'x1', 'y1', 'z1', 'w2', 'x2', 'y2', 'z2',\n",
        "                                        'w3', 'x3', 'y3', 'z3', 'w4', 'x4', 'y4', 'z4', 'w5', 'x5', 'y5', 'z5',\n",
        "                                        'w6', 'x6', 'y6', 'z6', 'w7', 'x7', 'y7', 'z7', 'w8', 'x8', 'y8', 'z8'])\n",
        "    del quat0, quat1, quat2, quat3, quat4, quat5, quat6, quat7, quat8\n",
        "\n",
        "    if(train==False):\n",
        "        step = n_time_steps//2\n",
        "\n",
        "    if(n_channels == 1):\n",
        "        for i in range(0, quat.shape[0] - n_time_steps, step): # Overlap\n",
        "            # Con listas y numpy\n",
        "            segments.append([])\n",
        "            segments[dim].append(quat.iloc[i: i + n_time_steps, :].values) # Si distinguimos entre sensores\n",
        "            labels.append(int(label-1))\n",
        "            dim+=1\n",
        "    else:\n",
        "        n_columns = int(36/n_channels)\n",
        "        for i in range(0, quat.shape[0] - n_time_steps, step):\n",
        "            segments.append([])\n",
        "            col = 0\n",
        "            for j in range(n_channels):\n",
        "                segments[dim].append([])\n",
        "                segments[dim][j].append(quat.iloc[i:i+n_time_steps,col:col+n_columns].values)\n",
        "                col+=n_columns\n",
        "            labels.append(label-1)\n",
        "            dim+=1\n",
        "\n",
        "\n",
        "    del quat\n",
        "\n",
        "    return segments, labels, dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yTYwjTrWtIV"
      },
      "outputs": [],
      "source": [
        "def load_quat(path, lim, train, n_channels):\n",
        "\n",
        "    step = n_time_steps//4  # n_time_steps/50 segundos de actividad y pasos de step/50 segundos (de overlap)\n",
        "\n",
        "    segments = []\n",
        "    labels = []\n",
        "\n",
        "    i=1\n",
        "    dim = 0\n",
        "    for filename in path:\n",
        "        print(\"Reading %s (%d/%d)                                                   \"%(filename, i, len(path)), end='\\r')\n",
        "        df = pd.read_csv(filename,sep=',',names=[\"QUAT\",\"w\",\"x\",\"y\",\"z\",\"timestamp\"])\n",
        "        label = int(filename[-6:-4])\n",
        "        for k in range(len(activities)):\n",
        "            if(label==activities[k]):\n",
        "                label=k+1\n",
        "\n",
        "        segments, labels, dim = sliding_window(df.iloc[:lim], n_time_steps, step, segments, labels, label, dim, train, n_channels)\n",
        "\n",
        "        i+=1\n",
        "\n",
        "    del df\n",
        "\n",
        "    return segments, labels\n",
        "\n",
        "\n",
        "def load_train_quat(filename, lim, n_channels):\n",
        "    return load_quat(filename, lim, True, n_channels)\n",
        "\n",
        "def load_test_quat(filename, lim, n_channels):\n",
        "    return load_quat(filename, lim, False, n_channels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql1QqbehWtIV"
      },
      "outputs": [],
      "source": [
        "def get_dataset(data_path, lim, batch_size, n_time_steps, train, valid, ds, n_channels):\n",
        "    if(train):\n",
        "        segments, labels = load_train_quat(data_path, lim, n_channels)\n",
        "    else:\n",
        "        segments, labels = load_test_quat(data_path, lim, n_channels)\n",
        "\n",
        "    print('Generating the dataset                                                   ')\n",
        "\n",
        "    array = np.asarray(segments, dtype = 'float32')\n",
        "    segments = np.reshape(array, (array.shape[0], n_channels, n_time_steps, int(36/n_channels)))\n",
        "    array = np.asarray(labels, dtype = 'int8')\n",
        "    labels = np.reshape(array, (array.shape[0], 1))\n",
        "\n",
        "    del array\n",
        "\n",
        "    # Map coninous dataset to categorical (One-Hot)\n",
        "    labels = keras.utils.to_categorical(labels, len(activities))\n",
        "\n",
        "    if(train):\n",
        "        print('-'*20 + 'TRAIN' + '-'*20)\n",
        "    elif(valid):\n",
        "        print('-'*18 + 'VALIDATION' + '-'*17)\n",
        "    else:\n",
        "        print('-'*20 + 'TEST' + '-'*21)\n",
        "\n",
        "    if(ds):\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((segments, labels))\n",
        "\n",
        "        # It's necessary to repeat our data for all epochs\n",
        "        dataset = dataset.batch(batch_size)\n",
        "\n",
        "        dataset = dataset.shuffle(segments.shape[0])\n",
        "\n",
        "        print('Dataset generated                                                        ')\n",
        "\n",
        "        return dataset, segments, labels\n",
        "    else:\n",
        "        np.random.seed(235)\n",
        "        # Shuffle in the first dimension\n",
        "        permutation = np.arange(0,segments.shape[0]-1)\n",
        "        np.random.shuffle(permutation)\n",
        "        segments = segments[permutation]\n",
        "        labels = labels[permutation]\n",
        "        print('Dataset generated                                                        ')\n",
        "\n",
        "        return segments, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCdv86qFWtIV"
      },
      "outputs": [],
      "source": [
        "global n_time_steps\n",
        "n_time_steps = 128\n",
        "\n",
        "def generator(s):\n",
        "    dataset = False # Set to True if you want a dataset or to False if you want np.arrays\n",
        "    batch_size = 32 # REAL batch_size\n",
        "    n_channels = 1 # It can be 1,4 or 9\n",
        "\n",
        "    subj = s[0][53:55]\n",
        "\n",
        "    seg, lab = get_dataset(s, ind_tr, batch_size, n_time_steps, True, False, dataset, n_channels)\n",
        "\n",
        "    print(seg.shape, lab.shape)\n",
        "\n",
        "    np.save('./def_raworientation_ALL_SENSORS/subject_video_'+subj+'_seg.npy', seg)\n",
        "    np.save('./def_raworientation_ALL_SENSORS/subject_video_'+subj+'_lab.npy', lab)\n",
        "\n",
        "    print('Files from subject ' + subj + ' saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNUSqo7nWtIV",
        "outputId": "20ce141c-5f8c-4c22-c417-f43bb20f8c83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 01 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O50IMV6WtIW",
        "outputId": "6b002da4-139f-49bd-916d-187bf38549b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 02 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv2DDigLWtIW",
        "outputId": "2df0ba46-6e1a-437c-ee80-07c22a64472d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 03 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTeU71PaWtIW",
        "outputId": "882a1a83-19f8-4927-b32f-16b3c67f3613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 05 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8qh-3d3WtIW",
        "outputId": "9663c7b5-b2e5-414d-aa84-2f35093645cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 08 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey1oj6MUWtIW",
        "outputId": "00c72b34-2acb-4dea-e491-e8e21631715b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 09 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNfHt4vgWtIW",
        "outputId": "92fb95f5-8a86-4aaa-de80-65cebdaafde3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 10 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiCKzdYQWtIW",
        "outputId": "e4170920-3322-44dc-9dcc-b0aaa735dcee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 11 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou0wCJxeWtIX",
        "outputId": "ad6b06ba-f761-4ccd-8c21-2368530d4826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 13 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMBPOdgCWtIa",
        "outputId": "e778d996-0e1d-45e7-e465-c97efe903fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 14 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzrKxVmlWtIa",
        "outputId": "190a87b1-7c1d-4258-b0a2-2c4dfe17cdf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 16 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBloLEjEWtIa",
        "outputId": "12b3fe77-78a4-496b-d0de-1fb3c4c24998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating the dataset                                                   _act_31.csv (11/11)                                                   \n",
            "--------------------TRAIN--------------------\n",
            "Dataset generated                                                        \n",
            "(98, 1, 128, 36) (98, 11)\n",
            "Files from subject 17 saved\n"
          ]
        }
      ],
      "source": [
        "generator(s17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RNCDS1wWtIa",
        "outputId": "2d421912-2aa0-45f1-e5b7-fd25141e37ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operación terminada.\n"
          ]
        }
      ],
      "source": [
        "print('Operación terminada.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}